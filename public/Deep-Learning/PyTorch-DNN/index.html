<!DOCTYPE html>
<!-- This site was created with Wowchemy. https://www.wowchemy.com -->
<!-- Last Published: January 4, 2024 --><html lang="en-us" >


<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  
  
  
    <meta name="generator" content="Wowchemy 5.7.0 for Hugo" />
  

  
  












  
  










  







  
  

  
  
  

  
  

  
  
    
    <script src="/js/mathjax-config.js"></script>
  

  

  <link rel="stylesheet" href="/css/vendor-bundle.min.047268c6dd09ad74ba54a0ba71837064.css" media="print" onload="this.media='all'">

  
  
  
    
    
      <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.2/css/academicons.min.css" integrity="sha512-KlJCpRsLf+KKu2VQa5vmRuClRFjxc5lXO03ixZt82HZUk41+1I0bD8KBSA0fY290ayMfWYI9udIqeOWSu1/uZg==" crossorigin="anonymous" media="print" onload="this.media='all'">
    

    
    
    
    
      
      
    
    
    

    
    
    

    

    
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
        <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js" integrity="" crossorigin="anonymous" async></script>
      
    
      
      

      
      

      
    
      
      

      
      

      
    
  

  
  
  
  
  
  
  <link rel="stylesheet" href="/css/wowchemy.d060e36f065b14306ff371728665eb02.css" />

  
  
  

  
  
  
  
  
  
  
    
    
    <link rel="stylesheet" href="/css/libs/chroma/dracula.min.css" title="hl-light" media="print" onload="this.media='all'" >
    <link rel="stylesheet" href="/css/libs/chroma/dracula.min.css" title="hl-dark" media="print" onload="this.media='all'" disabled>
  

  
  

  <meta name="google-site-verification" content="Zv4l_ljWZhu4o0Z-kfZwQmuokpt40AvKXA78N8kynpc" />





<script async src="https://www.googletagmanager.com/gtag/js?id=G-55GQYC5GYC"></script>
<script>
  window.dataLayer = window.dataLayer || [];

  function gtag() {
      dataLayer.push(arguments);
  }

  function trackOutboundLink(url, target) {
    gtag('event', 'click', {
         'event_category': 'outbound',
         'event_label': url,
         'transport_type': 'beacon',
         'event_callback': function () {
           if (target !== '_blank') {
             document.location = url;
           }
         }
    });
    console.debug("Outbound link clicked: " + url);
  }

  function onClickCallback(event) {
    if ((event.target.tagName !== 'A') || (event.target.host === window.location.host)) {
      return;
    }
    trackOutboundLink(event.target, event.target.getAttribute('target'));  
  }

  gtag('js', new Date());
  gtag('config', 'G-55GQYC5GYC', {});
  gtag('set', {'cookie_flags': 'SameSite=None;Secure'});

  
  document.addEventListener('click', onClickCallback, false);
</script>




<script>
  (function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
  new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
  j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
  'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
  })(window,document,'script','dataLayer','G-55GQYC5GYC');
</script>




















  
  
  






  <meta name="author" content="Arman Asgharpoor Golroudbari" />





  

<meta name="description" content="Introduction üöÄ Dive into the Exciting World of Deep Neural Networks with PyTorch! ü§ñüî•
Hey there, fellow tech enthusiast! ü§ì Ever felt like PyTorch is a bit of a puzzle, unlike its more user-friendly counterparts?" />



<link rel="alternate" hreflang="en-us" href="https://armanasq.github.io/Deep-Learning/PyTorch-DNN/" />
<link rel="canonical" href="https://armanasq.github.io/Deep-Learning/PyTorch-DNN/" />



  <link rel="manifest" href="/manifest.webmanifest" />



<link rel="icon" type="image/png" href="/media/icon_hu3a1b1aacf1bb12033635935a8f8a9863_117561_32x32_fill_lanczos_center_3.png" />
<link rel="apple-touch-icon" type="image/png" href="/media/icon_hu3a1b1aacf1bb12033635935a8f8a9863_117561_180x180_fill_lanczos_center_3.png" />

<meta name="theme-color" content="#1565c0" />










  
  






<meta property="twitter:card" content="summary" />

  <meta property="twitter:site" content="@wowchemy" />
  <meta property="twitter:creator" content="@wowchemy" />
<meta property="twitter:image" content="https://armanasq.github.io/media/icon_hu3a1b1aacf1bb12033635935a8f8a9863_117561_512x512_fill_lanczos_center_3.png" />
<meta property="og:site_name" content="" />
<meta property="og:url" content="https://armanasq.github.io/Deep-Learning/PyTorch-DNN/" />
<meta property="og:title" content="Deep Neural Network Implementation Using PyTorch | " />
<meta property="og:description" content="Introduction üöÄ Dive into the Exciting World of Deep Neural Networks with PyTorch! ü§ñüî•
Hey there, fellow tech enthusiast! ü§ì Ever felt like PyTorch is a bit of a puzzle, unlike its more user-friendly counterparts?" /><meta property="og:image" content="https://armanasq.github.io/media/icon_hu3a1b1aacf1bb12033635935a8f8a9863_117561_512x512_fill_lanczos_center_3.png" /><meta property="og:locale" content="en-us" />

  
    <meta
      property="article:published_time"
      content="2023-05-01T00:00:00&#43;00:00"
    />
  
  
    <meta property="article:modified_time" content="2023-05-01T00:00:00&#43;00:00">
  






    






  




<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://armanasq.github.io/Deep-Learning/PyTorch-DNN/"
  },
  "headline": "Deep Neural Network Implementation Using PyTorch",
  
  "datePublished": "2023-05-01T00:00:00Z",
  "dateModified": "2023-05-01T00:00:00Z",
  
  "author": {
    "@type": "Person",
    "name": "Arman Asgharpoor Golroudbari"
  },
  
  "publisher": {
    "@type": "Organization",
    "name": "",
    "logo": {
      "@type": "ImageObject",
      "url": "https://armanasq.github.io/media/icon_hu3a1b1aacf1bb12033635935a8f8a9863_117561_192x192_fill_lanczos_center_3.png"
    }
  },
  "description": "Introduction üöÄ Dive into the Exciting World of Deep Neural Networks with PyTorch! ü§ñüî•\nHey there, fellow tech enthusiast! ü§ì Ever felt like PyTorch is a bit of a puzzle, unlike its more user-friendly counterparts?"
}
</script>

  

  




  
  
  

  
  

  


  
  <title>Deep Neural Network Implementation Using PyTorch | </title>

  
  
  
  











</head>


<body id="top" data-spy="scroll" data-offset="70" data-target="#TableOfContents" class="page-wrapper   " data-wc-page-id="a9f37b0d8a4fc07b7fd18e177567dc8f" >

  
  
  
  
  
  
  
  
  
  <script src="/js/wowchemy-init.min.ec9d49ca50e4b80bdb08f0417a28ed84.js"></script>

  


<aside class="search-modal" id="search">
  <div class="container">
    <section class="search-header">

      <div class="row no-gutters justify-content-between mb-3">
        <div class="col-6">
          <h1>Search</h1>
        </div>
        <div class="col-6 col-search-close">
          <a class="js-search" href="#" aria-label="Close"><i class="fas fa-times-circle text-muted" aria-hidden="true"></i></a>
        </div>
      </div>

      <div id="search-box">
        
        <input name="q" id="search-query" placeholder="Search..." autocapitalize="off"
        autocomplete="off" autocorrect="off" spellcheck="false" type="search" class="form-control"
        aria-label="Search...">
        
      </div>

      
      

      

    </section>
    <section class="section-search-results">

      <div id="search-hits">
        
      </div>

    </section>
  </div>
</aside>



  <div class="page-header header--fixed">
  
  
  
  
  












<header>
  <nav class="navbar navbar-expand-lg navbar-light compensate-for-scrollbar" id="navbar-main">
    <div class="container-xl">

      
      <div class="d-none d-lg-inline-flex">
        <a class="navbar-brand" href="/"></a>
      </div>
      

      
      <button type="button" class="navbar-toggler" data-toggle="collapse"
              data-target="#navbar-content" aria-controls="navbar-content" aria-expanded="false" aria-label="Toggle navigation">
      <span><i class="fas fa-bars"></i></span>
      </button>
      

      
      <div class="navbar-brand-mobile-wrapper d-inline-flex d-lg-none">
        <a class="navbar-brand" href="/"></a>
      </div>
      

      
      
      <div class="navbar-collapse main-menu-item collapse justify-content-start" id="navbar-content">

        
        <ul class="navbar-nav d-md-inline-flex">
          

          

          
          
          
            
          

          

          
          
          
          

          
            
              
              
            
            
              
              
              
                
              
              
            
          

          <li class="nav-item">
            <a class="nav-link " href="/#about"><span>Home</span></a>
          </li>

          
          

          

          
          
          
            
          

          

          
          
          
          

          
            
              
              
            
            
          

          <li class="nav-item">
            <a class="nav-link " href="/robotic"><span>Robotic</span></a>
          </li>

          
          

          

          
          
          
            
          

          

          
          
          
          

          
            
              
              
            
            
              
              
              
                
              
              
            
          

          <li class="nav-item">
            <a class="nav-link " href="/#posts"><span>Posts</span></a>
          </li>

          
          

          

          
          
          
            
          

          

          
          
          
          

          
            
              
              
            
            
              
              
              
                
              
              
            
          

          <li class="nav-item">
            <a class="nav-link " href="/#projects"><span>Projects</span></a>
          </li>

          
          

          

          
          
          
            
          

          

          
          
          
          

          
            
              
              
            
            
              
              
              
                
              
              
            
          

          <li class="nav-item">
            <a class="nav-link " href="/#talks"><span>Talks</span></a>
          </li>

          
          

          

          
          
          
            
          

          

          
          
          
          

          
            
              
              
            
            
          

          <li class="nav-item">
            <a class="nav-link " href="/publication"><span>Publications</span></a>
          </li>

          
          

          

          
          
          
            
          

          

          
          
          
          

          
            
              
              
            
            
          

          <li class="nav-item">
            <a class="nav-link " href="/certificates"><span>Certificates</span></a>
          </li>

          
          

          

          
          
          
            
          

          

          
          
          
          

          
            
              
              
            
            
              
              
              
                
              
              
            
          

          <li class="nav-item">
            <a class="nav-link " href="/#contact"><span>Contact</span></a>
          </li>

          
          

        

          
        </ul>
      </div>

      <ul class="nav-icons navbar-nav flex-row ml-auto d-flex pl-md-2">

        
        
          
            
            <li class="nav-item d-none d-lg-inline-flex">
              <a class="nav-link" href="mailto:a.asgharpoor1993@gmail.com" data-toggle="tooltip" data-placement="bottom" title="Drop me an email."  aria-label="Drop me an email.">
                <i class="fas fa-envelope" aria-hidden="true"></i>
              </a>
            </li>
          
            
            <li class="nav-item d-none d-lg-inline-flex">
              <a class="nav-link" href="https://github.com/armanasq" data-toggle="tooltip" data-placement="bottom" title="Follow Me on GitHub." target="_blank" rel="noopener" aria-label="Follow Me on GitHub.">
                <i class="fab fa-github" aria-hidden="true"></i>
              </a>
            </li>
          
        

        
        
        
        <li class="nav-item">
          <a class="nav-link js-search" href="#" aria-label="Search"><i class="fas fa-search" aria-hidden="true"></i></a>
        </li>
        

        
        
        
        <li class="nav-item dropdown theme-dropdown">
          <a href="#" class="nav-link" data-toggle="dropdown" aria-haspopup="true" aria-label="Display preferences">
            <i class="fas fa-moon" aria-hidden="true"></i>
          </a>
          <div class="dropdown-menu">
            <a href="#" class="dropdown-item js-set-theme-light">
              <span>Light</span>
            </a>
            <a href="#" class="dropdown-item js-set-theme-dark">
              <span>Dark</span>
            </a>
            <a href="#" class="dropdown-item js-set-theme-auto">
              <span>Automatic</span>
            </a>
          </div>
        </li>
        

        
        

      </ul>

    </div>
  </nav>
</header>


  </div>

  <div class="page-body">
    
    
    

    <article class="article">

  













  

  
  
  
<div class="article-container pt-3">
  <h1>Deep Neural Network Implementation Using PyTorch</h1>

  

  
    


<div class="article-metadata">

  
  

  
  <span class="article-date">
    
    
      
    
    May 1, 2023
  </span>
  

  

  
  <span class="middot-divider"></span>
  <span class="article-reading-time">
    34 min read
  </span>
  

  
  
  
  

  
  

</div>

    




<div class="btn-links mb-3">
  
  








  






  
  
    
  
<a class="btn btn-outline-primary btn-page-header" href="https://colab.research.google.com/drive/1B0bRq3XpbDGOuVRi8q3ycNiR_gatfBH8?usp=sharing" target="_blank" rel="noopener">
  Code
</a>













  
  
  
    
  
  
  
  
  
    
  
  <a class="btn btn-outline-primary btn-page-header" href="https://github.com/Armanasq/Deep-Learning-Tutorial/blob/main/PyTorch/Deep_Neural_Network_Implementation_Using_PyTorch.ipynb" target="_blank" rel="noopener">
    <i class="fab fa-github mr-1"></i>Project Code</a>


</div>


  
</div>



  <div class="article-container">

    <div class="article-style">
      <div style='background-color: rgba(225,225,225,0.48); padding: 10px; border-radius:15px;'>
<p>















<figure  >
  <div class="d-flex justify-content-center">
    <div class="w-100" ><img src="/PyTorch/pytorch.png" alt="png" loading="lazy" data-zoomable /></div>
  </div></figure>
</p>
</div>
<h2 id="introduction">Introduction</h2>
<p>üöÄ Dive into the Exciting World of Deep Neural Networks with PyTorch! ü§ñüî•</p>
<p>Hey there, fellow tech enthusiast! ü§ì Ever felt like PyTorch is a bit of a puzzle, unlike its more user-friendly counterparts? Well, fret not, because we&rsquo;re here to spice up your deep learning journey! üéâ</p>
<p>‚ö° Introducing the &ldquo;PyTorch Deep Dive&rdquo; Series ‚ö°</p>
<p>Buckle up, because we&rsquo;re taking you on a whirlwind adventure through the realm of implementing Deep Neural Networks using PyTorch. üåü Whether you&rsquo;re a fresh-faced researcher venturing into the deep learning domain or a pro switching up your frameworks, this series has your back!</p>
<p>üìö It&rsquo;s Not Your Typical Tutorial üìö</p>
<p>Before we get all technical, let&rsquo;s set the stage. We&rsquo;re not going to baby you through PyTorch basics. This isn&rsquo;t your run-of-the-mill PyTorch tutorial; this is where we show you how to wield the power of PyTorch to craft magnificent Deep Neural Networks. So, if you&rsquo;ve got your basics down with libraries like NumPy and Matplotlib, you&rsquo;re golden!</p>
<p>üß† Deep Dive, Literally üß†</p>
<p>Hold up! This isn&rsquo;t Deep Learning 101 either. We&rsquo;re diving straight into the meaty part ‚Äì building the real deal! So if you&rsquo;re nodding your head to terms like Neural Networks and the magic of backpropagation, you&rsquo;re all set to sail.</p>
<p>üåà Practical Deep Learning FTW üåà</p>
<p>Picture this: in our first tutorial, we&rsquo;re going hands-on with a super simple deep neural network example using PyTorch. üöÄ Trust us, learning through examples is the secret sauce! üçîüçü After all, who doesn&rsquo;t love breaking down complex problems with relatable examples?</p>
<p>üéÆ Tutorial Level 1: PyTorch Essentials üéÆ</p>
<p>Ready, steady, go! üèÅ We&rsquo;re kicking things off by giving you the lowdown on PyTorch ‚Äì why you should use it, what makes it tick, and why it&rsquo;s your trusty sidekick for the deep learning journey. Then, brace yourself for some action! We&rsquo;re jumping into a fun classification task. Think of it as a sneak peek into the PyTorch universe: how models are born, trained, and put to the test.</p>
<p>Feeling a bit overwhelmed? No worries at all! Everyone starts somewhere, and this is your starting line. With a sprinkle of patience, a dash of trial and error, and a dollop of dedication, you&rsquo;ll be whizzing through this in no time.</p>
<p>üöÄ Elevate Your Neural Network Game üöÄ</p>
<p>Here&rsquo;s the deal: we&rsquo;re covering the nitty-gritty, from foundational concepts to crafting your network architecture. By the end of this tutorial, you&rsquo;ll be waving your PyTorch wand to create powerful deep learning models. ü™Ñ‚ú®</p>
<p>Ready to embark on this journey? We thought so! Head over to the Google Colab notebook at the link below and let&rsquo;s dive into the world of PyTorch-powered Deep Neural Networks together:</p>
<p>üîó <a href="https://colab.research.google.com/drive/1B0bRq3XpbDGOuVRi8q3ycNiR_gatfBH8?usp=sharing" target="_blank" rel="noopener">Notebook Link</a></p>
<p>Let&rsquo;s make those neurons dance and those models shine! üï∫üíÉüíª</p>


<details class="toc-inpage d-print-none  " open>
  <summary class="font-weight-bold">Table of Contents</summary>
  <nav id="TableOfContents">
  <ul>
    <li><a href="#introduction">Introduction</a>
      <ul>
        <li><a href="#0-whats-the-hype-about-pytorch">0. What&rsquo;s the Hype about PyTorch?</a></li>
        <li><a href="#01-the-why-is-pytorch-awesome-showdown">0.1 The &ldquo;Why-Is-PyTorch-Awesome&rdquo; Showdown</a></li>
        <li><a href="#02-the-code-it-like-its-hot-vibe">0.2 The &ldquo;Code It Like It&rsquo;s Hot&rdquo; Vibe</a></li>
        <li><a href="#03-pytorch-vs-the-universe">0.3 PyTorch vs. the Universe</a></li>
      </ul>
    </li>
    <li><a href="#1-prerequisites">1. Prerequisites</a></li>
    <li><a href="#2-getting-started-with-pytorch">2. Getting Started with PyTorch</a>
      <ul>
        <li><a href="#installation">Installation</a></li>
        <li><a href="#importing-required-libraries">Importing Required Libraries</a></li>
        <li><a href="#setting-up-the-gpu-optional">Setting up the GPU (Optional)</a></li>
      </ul>
    </li>
    <li><a href="#3-dataset-preparation">3. Dataset Preparation</a>
      <ul>
        <li><a href="#data-loading">Data Loading</a></li>
        <li><a href="#data-preprocessing">Data Preprocessing</a></li>
        <li><a href="#train-validation-test-split">Train-Validation-Test Split</a></li>
      </ul>
    </li>
    <li><a href="#4-model-architecture-design">4. Model Architecture Design</a>
      <ul>
        <li><a href="#neural-network-layers">Neural Network Layers</a></li>
        <li><a href="#activation-functions">Activation Functions</a></li>
        <li><a href="#loss-functions">Loss Functions</a></li>
        <li><a href="#optimizers">Optimizers</a></li>
        <li><a href="#hyperparameters">Hyperparameters</a></li>
      </ul>
    </li>
    <li><a href="#5-building-the-deep-neural-network-model">5. Building the Deep Neural Network Model</a>
      <ul>
        <li><a href="#defining-the-model-class">Defining the Model Class</a></li>
        <li><a href="#initializing-the-model">Initializing the Model</a></li>
      </ul>
    </li>
    <li><a href="#6-training-the-model">6. Training the Model</a>
      <ul>
        <li><a href="#setting-up-training-parameters">Setting up Training Parameters</a></li>
        <li><a href="#defining-the-loss-function">Defining the Loss Function</a></li>
        <li><a href="#selecting-the-optimizer">Selecting the Optimizer</a></li>
        <li><a href="#define-the-number-of-epochs">Define the Number of Epochs</a></li>
        <li><a href="#define-the-batch-size">Define the Batch Size</a></li>
        <li><a href="#creat-dataset-loader">Creat Dataset Loader</a></li>
        <li><a href="#training-the-model">Training the Model</a></li>
        <li><a href="#monitoring-training-progress">Monitoring Training Progress</a></li>
      </ul>
    </li>
    <li><a href="#7-evaluating-the-model">7. Evaluating the Model</a>
      <ul>
        <li><a href="#testing-the-model">Testing the Model</a></li>
        <li><a href="#model-evaluation-metrics">Model Evaluation Metrics</a></li>
      </ul>
    </li>
    <li><a href="#8-improving-model-performance">8. Improving Model Performance</a>
      <ul>
        <li><a href="#regularization-techniques">Regularization Techniques</a></li>
        <li><a href="#hyperparameter-tuning">Hyperparameter Tuning</a></li>
        <li><a href="#data-augmentation-1">Data Augmentation</a></li>
        <li><a href="#transfer-learning">Transfer Learning</a></li>
      </ul>
    </li>
    <li><a href="#9-saving-and-loading-models">9. Saving and Loading Models</a>
      <ul>
        <li><a href="#saving-the-model">Saving the Model</a></li>
        <li><a href="#loading-the-model">Loading the Model</a></li>
      </ul>
    </li>
    <li><a href="#10-conclusion">10. Conclusion</a></li>
    <li><a href="#11-references">11. References</a></li>
  </ul>
</nav>
</details>

<hr>
<h3 id="0-whats-the-hype-about-pytorch">0. What&rsquo;s the Hype about PyTorch?</h3>
<p>PyTorch, the brainchild of the whizzes at Facebook&rsquo;s AI Research lab (FAIR), is THE open-source framework empowering deep learning daredevils like you. üé©‚ú® Whether you&rsquo;re a research maestro or a coding ninja, PyTorch is your trusty sidekick for crafting and taming deep neural networks that conquer complexity like champs.</p>
<h3 id="01-the-why-is-pytorch-awesome-showdown">0.1 The &ldquo;Why-Is-PyTorch-Awesome&rdquo; Showdown</h3>
<p>Hold onto your code hats, because PyTorch packs a punch like no other! Here are the dazzling stars that set PyTorch on the red carpet of deep learning fame:</p>
<ul>
<li>
<p><strong>Python Power-Up</strong>: PyTorch speaks fluent Python and cozies up with its libraries, making it the ultimate wingman for your Python-powered projects. üêçüìö</p>
</li>
<li>
<p><strong>Facebook&rsquo;s Fav</strong>: You know it&rsquo;s a superstar when even Facebook themselves use it for their deep learning endeavors. üì∏üëë</p>
</li>
<li>
<p><strong>User-Friendly Vibes</strong>: PyTorch brings the party with an API so intuitive, even your pet parrot could grasp it. ü¶úüíÉ</p>
</li>
<li>
<p><strong>Graphs on the Fly</strong>: Ever seen a graph build itself while the code dances? PyTorch&rsquo;s dynamic computational graphs are the coolest party trick in town. üï∫üìä</p>
</li>
<li>
<p><strong>Speed Racer</strong>: PyTorch zips through computations faster than a caffeinated cheetah, giving you a turbo-charged coding experience. ‚ö°üêÜ</p>
</li>
<li>
<p><strong>GPU Awesomeness</strong>: With CUDA at its side, PyTorch flexes its muscles on GPUs for lightning-fast execution. Cue applause for speed and power! üöÄüí•</p>
</li>
<li>
<p><strong>Community Carnival</strong>: Join the PyTorch parade with a bustling community that brings you libraries, tools, and pre-trained models galore! From <code>torchvision</code> for vision quests to <code>transformers</code> for language escapades, PyTorch&rsquo;s got you covered. üéâüìö</p>
</li>
<li>
<p><strong>Deploy Delights</strong>: PyTorch&rsquo;s toolkit ensures your models hit the streets with style. Whether you&rsquo;re sending them to mobile realms or web wonderlands, PyTorch makes sure they&rsquo;re dressed to impress. üöÄüåê</p>
</li>
</ul>
<h3 id="02-the-code-it-like-its-hot-vibe">0.2 The &ldquo;Code It Like It&rsquo;s Hot&rdquo; Vibe</h3>
<p>Welcome to the land of Pythonic perfection! üéâüêç PyTorch embraces Python&rsquo;s charm, giving you a playground of simplicity and elegance. It&rsquo;s a place where you can code complex computations with the grace of a swan in a tutu. ü¶¢‚ú®</p>
<h3 id="03-pytorch-vs-the-universe">0.3 PyTorch vs. the Universe</h3>
<p>Ah, the grand showdown! PyTorch takes on the titans like TensorFlow, Keras, and Caffe. While each has its own fan club, PyTorch stands out like a supernova in a deep learning galaxy:</p>
<ul>
<li>
<p><strong>Dynamic vs. Static</strong>: PyTorch&rsquo;s dynamic graph brings the house down, letting you tweak, twist, and turn your models on the fly. Static graphs, eat your heart out! üíÉüé©</p>
</li>
<li>
<p><strong>Pythonic Powers</strong>: PyTorch speaks your language, letting you express complex ideas with Pythonic flair. Say goodbye to tangled code vines! üêç‚ú®</p>
</li>
<li>
<p><strong>Debugging Sorcery</strong>: PyTorch has your back with debugging tricks up its sleeves. Spot bugs, squash them, and watch your models shine! üêûüîÆ</p>
</li>
</ul>
<table>
<thead>
<tr>
<th></th>
<th>PyTorch</th>
<th>TensorFlow</th>
<th>Keras</th>
<th>Theano</th>
<th>Lasagne</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Computational Graph</strong></td>
<td>Dynamic</td>
<td>Static</td>
<td>Static</td>
<td>Symbolic</td>
<td>Symbolic</td>
</tr>
<tr>
<td><strong>Automatic Differentiation</strong></td>
<td>Yes</td>
<td>Yes</td>
<td>Yes</td>
<td>Yes</td>
<td>Yes</td>
</tr>
<tr>
<td><strong>GPU Acceleration</strong></td>
<td>Yes</td>
<td>Yes</td>
<td>Yes</td>
<td>Yes</td>
<td>Yes</td>
</tr>
<tr>
<td><strong>Pythonic API</strong></td>
<td>Yes</td>
<td>Yes</td>
<td>Yes</td>
<td>Partial</td>
<td>No</td>
</tr>
<tr>
<td><strong>Static Graph Optimization</strong></td>
<td>TorchScript</td>
<td>XLA, Graph Transform Tool (GTT)</td>
<td>N/A</td>
<td>N/A</td>
<td>N/A</td>
</tr>
<tr>
<td><strong>TensorBoard Integration</strong></td>
<td>Yes</td>
<td>Yes</td>
<td>Yes</td>
<td>No</td>
<td>No</td>
</tr>
<tr>
<td><strong>Multi-GPU Support</strong></td>
<td>Yes</td>
<td>Yes</td>
<td>Yes</td>
<td>No</td>
<td>No</td>
</tr>
<tr>
<td><strong>Model Serving and Deployment</strong></td>
<td>TorchServe, TorchScript</td>
<td>TensorFlow Serving, TensorFlow Lite</td>
<td>TensorFlow Serving, TensorFlow Lite</td>
<td>N/A</td>
<td>N/A</td>
</tr>
<tr>
<td><strong>Parallel and Distributed Training</strong></td>
<td>DistributedDataParallel, DataParallel</td>
<td>tf.distribute.Strategy</td>
<td>tf.distribute.Strategy</td>
<td>No</td>
<td>No</td>
</tr>
<tr>
<td><strong>Dynamic Neural Networks</strong></td>
<td>Yes</td>
<td>No</td>
<td>No</td>
<td>No</td>
<td>No</td>
</tr>
<tr>
<td><strong>Mobile and Embedded Deployment</strong></td>
<td>PyTorch Mobile, PyTorch for iOS and Android</td>
<td>TensorFlow Lite</td>
<td>TensorFlow Lite</td>
<td>No</td>
<td>No</td>
</tr>
<tr>
<td><strong>Quantization Support</strong></td>
<td>Yes</td>
<td>TensorFlow Model Optimization Toolkit</td>
<td>TensorFlow Model Optimization Toolkit</td>
<td>No</td>
<td>No</td>
</tr>
<tr>
<td><strong>Rich Ecosystem and Community</strong></td>
<td>Yes</td>
<td>Yes</td>
<td>Yes</td>
<td>Limited</td>
<td>Limited</td>
</tr>
<tr>
<td><strong>Integration with Other Libraries</strong></td>
<td>TorchVision, TorchText, Transformers</td>
<td>TensorFlow Hub, TensorFlow Datasets</td>
<td>TensorFlow Hub, TensorFlow Datasets</td>
<td>Limited</td>
<td>Limited</td>
</tr>
<tr>
<td><strong>Support and Documentation</strong></td>
<td>Strong</td>
<td>Strong</td>
<td>Strong</td>
<td>Limited</td>
<td>Limited</td>
</tr>
</tbody>
</table>
<p>Behold the enchanting journey of implementing deep learning in PyTorch, as illustrated below:</p>
<ul>
<li>PyTorch Workflow for Deep Learning
<ul>
<li>Data Preparation:
<ul>
<li>Load and preprocess the dataset:
<ul>
<li>Load data from files or libraries.</li>
<li>Handle missing values and outliers.</li>
<li>Normalize or scale features if necessary.</li>
<li>Convert categorical variables to numerical representations.</li>
</ul>
</li>
<li>Split the dataset:
<ul>
<li>Divide data into training, validation, and test sets.</li>
<li>Shuffle the data to ensure randomness.</li>
<li>Determine appropriate ratios for each set.</li>
</ul>
</li>
</ul>
</li>
<li>Model Definition:
<ul>
<li>Choose a neural network architecture:
<ul>
<li>Decide on the type of neural network (e.g., feedforward, convolutional, recurrent).</li>
<li>Determine the number of layers and units per layer.</li>
<li>Choose activation functions for hidden layers.</li>
</ul>
</li>
<li>Define the model&rsquo;s architecture using PyTorch&rsquo;s nn.Module:
<ul>
<li>Create a custom class inheriting from nn.Module.</li>
<li>Define layers and operations in the <strong>init</strong> method.</li>
<li>Implement the forward pass in the forward method.</li>
</ul>
</li>
</ul>
</li>
<li>Loss Function and Optimizer:
<ul>
<li>Select a loss function for the task</li>
<li>Choose an optimizer</li>
<li>Define learning rate and other hyperparameters.</li>
</ul>
</li>
<li>Training Loop:
<ul>
<li>Iterate over training dataset in batches:
<ul>
<li>Divide data into batches for efficient computation.</li>
<li>Use DataLoader for automatic batching and shuffling.</li>
</ul>
</li>
<li>Forward pass:
<ul>
<li>Pass a batch through the model to obtain predictions.</li>
</ul>
</li>
<li>Calculate loss:
<ul>
<li>Compare predictions to actual target values.</li>
<li>Compute the loss using the selected loss function.</li>
</ul>
</li>
<li>Backward pass:
<ul>
<li>Calculate gradients using automatic differentiation.</li>
<li>Backpropagate gradients through the network.</li>
</ul>
</li>
<li>Update model parameters:
<ul>
<li>Use the optimizer to update weights based on gradients.</li>
</ul>
</li>
</ul>
</li>
<li>Validation:
<ul>
<li>Iterate over validation dataset in batches:
<ul>
<li>Similar to the training loop but with validation data.</li>
<li>Calculate validation loss and any desired metrics.</li>
<li>Evaluate the model&rsquo;s performance on unseen data.</li>
</ul>
</li>
</ul>
</li>
<li>Early Stopping (optional):
<ul>
<li>Monitor validation loss during training:
<ul>
<li>Track validation loss throughout epochs.</li>
<li>Compare current loss to previous values.</li>
</ul>
</li>
<li>Stop if validation loss plateaus or increases:
<ul>
<li>Implement a stopping criterion to prevent overfitting.</li>
<li>Restore the model to the best-performing state.</li>
</ul>
</li>
</ul>
</li>
<li>Testing:
<ul>
<li>Iterate over test dataset in batches:
<ul>
<li>Similar to validation and training loops.</li>
<li>Calculate test loss and relevant metrics.</li>
<li>Assess the final model&rsquo;s performance on unseen data.</li>
</ul>
</li>
</ul>
</li>
<li>Visualization and Analysis (optional):
<ul>
<li>Plot training and validation curves:
<ul>
<li>Create graphs of loss and metrics over epochs.</li>
</ul>
</li>
<li>Visualize model predictions on sample data:
<ul>
<li>Display model predictions alongside actual data.</li>
<li>Gain insights into how the model behaves.</li>
</ul>
</li>
</ul>
</li>
<li>Save the model.</li>
</ul>
</li>
</ul>
<div class="markmap" style="height: 500px;">

<pre>- PyTorch Workflow for Deep Learning
  - Data Preparation:
      - Load and preprocess the dataset:
          - Load data from files or libraries.
          - Handle missing values and outliers.
          - Normalize or scale features if necessary.
          - Convert categorical variables to numerical representations.
      - Split the dataset:
          - Divide data into training, validation, and test sets.
          - Shuffle the data to ensure randomness.
          - Determine appropriate ratios for each set.
  - Model Definition:
      - Choose a neural network architecture:
          - Decide on the type of neural network (e.g., feedforward, convolutional, recurrent).
          - Determine the number of layers and units per layer.
          - Choose activation functions for hidden layers.
      - Define the model's architecture using PyTorch's nn.Module:
          - Create a custom class inheriting from nn.Module.
          - Define layers and operations in the __init__ method.
          - Implement the forward pass in the forward method.
  - Loss Function and Optimizer:
      - Select a loss function for the task
      - Choose an optimizer
      - Define learning rate and other hyperparameters.
  - Training Loop:
      - Iterate over training dataset in batches:
          - Divide data into batches for efficient computation.
          - Use DataLoader for automatic batching and shuffling.
      - Forward pass:
          - Pass a batch through the model to obtain predictions.
      - Calculate loss:
          - Compare predictions to actual target values.
          - Compute the loss using the selected loss function.
      - Backward pass:
          - Calculate gradients using automatic differentiation.
          - Backpropagate gradients through the network.
      - Update model parameters:
          - Use the optimizer to update weights based on gradients.
  - Validation:
      - Iterate over validation dataset in batches:
          - Similar to the training loop but with validation data.
          - Calculate validation loss and any desired metrics.
          - Evaluate the model's performance on unseen data.
  - Early Stopping (optional):
      - Monitor validation loss during training:
          - Track validation loss throughout epochs.
          - Compare current loss to previous values.
      - Stop if validation loss plateaus or increases:
          - Implement a stopping criterion to prevent overfitting.
          - Restore the model to the best-performing state.
  - Testing:
      - Iterate over test dataset in batches:
          - Similar to validation and training loops.
          - Calculate test loss and relevant metrics.
          - Assess the final model's performance on unseen data.
  - Visualization and Analysis (optional):
      - Plot training and validation curves:
          - Create graphs of loss and metrics over epochs.
      - Visualize model predictions on sample data:
          - Display model predictions alongside actual data.
          - Gain insights into how the model behaves.
  - Save the model.</pre>
</div>

<h2 id="1-prerequisites">1. Prerequisites</h2>
<p>Before diving into deep neural network implementation with PyTorch, it is essential to have a basic understanding of the following concepts:</p>
<ul>
<li>Python programming language</li>
<li>Machine learning fundamentals</li>
<li>Neural networks and their architectures</li>
</ul>
<h2 id="2-getting-started-with-pytorch">2. Getting Started with PyTorch</h2>
<h3 id="installation">Installation</h3>
<p>To install PyTorch, you can use <code>pip</code> or <code>conda</code>. Open a terminal and run the following command:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-shell" data-lang="shell"><span class="line"><span class="cl">pip install torch torchvision
</span></span></code></pre></div><p>Also, you can find the comprehensive tutorial on get started in the <a href="https://pytorch.org/get-started/locally/" target="_blank" rel="noopener">official page</a>.</p>
<h3 id="importing-required-libraries">Importing Required Libraries</h3>
<p>In your Python script or notebook, import the necessary libraries as follows:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">torch</span>
</span></span><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>
</span></span><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">torch.optim</span> <span class="k">as</span> <span class="nn">optim</span>
</span></span><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">torchvision.transforms</span> <span class="k">as</span> <span class="nn">transforms</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">DataLoader</span>
</span></span></code></pre></div><h3 id="setting-up-the-gpu-optional">Setting up the GPU (Optional)</h3>
<p>If you have access to a GPU, PyTorch can leverage its power to accelerate computations. To utilize the GPU, ensure that you have the appropriate NVIDIA drivers installed. You can then enable GPU support in PyTorch by adding the following code:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">&#34;cuda&#34;</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s2">&#34;cpu&#34;</span><span class="p">)</span>
</span></span></code></pre></div><h2 id="3-dataset-preparation">3. Dataset Preparation</h2>
<p>In following, we will explore the intricate process of dataset loading, preprocessing, and train-validation-test splitting. We will focus on the MNIST dataset as an illustrative example. By following these steps, you will gain an in-depth understanding of dataset preparation in the context of deep learning.</p>
<h3 id="data-loading">Data Loading</h3>
<p>Loading the dataset is the initial step in the data preparation pipeline. PyTorch&rsquo;s <code>torchvision</code> module provides a range of functions for automatically downloading and loading popular datasets, including MNIST, CIFAR and etc. The MNIST dataset comprises grayscale images of handwritten digits, with each image labeled from 0 to 9.</p>
<p>To load the MNIST dataset using PyTorch, execute the following code:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">torchvision.datasets</span> <span class="k">as</span> <span class="nn">datasets</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># Define the root directory for dataset storage</span>
</span></span><span class="line"><span class="cl"><span class="n">data_root</span> <span class="o">=</span> <span class="s2">&#34;./data&#34;</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># Download and load the MNIST training set</span>
</span></span><span class="line"><span class="cl"><span class="n">train_set</span> <span class="o">=</span> <span class="n">datasets</span><span class="o">.</span><span class="n">MNIST</span><span class="p">(</span><span class="n">root</span><span class="o">=</span><span class="n">data_root</span><span class="p">,</span> <span class="n">train</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">download</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># Download and load the MNIST test set</span>
</span></span><span class="line"><span class="cl"><span class="n">test_set</span> <span class="o">=</span> <span class="n">datasets</span><span class="o">.</span><span class="n">MNIST</span><span class="p">(</span><span class="n">root</span><span class="o">=</span><span class="n">data_root</span><span class="p">,</span> <span class="n">train</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">download</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span></span></code></pre></div><p>In the above code, we utilize the <code>datasets.MNIST</code> class to download and load the MNIST dataset. The <code>root</code> parameter specifies the directory where the dataset will be stored. By setting <code>train=True</code>, we load the training set, while <code>train=False</code> indicates the test set.</p>
<p>You can visualize the dataset by:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
</span></span><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">math</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># Define the number of rows and columns for the subplots</span>
</span></span><span class="line"><span class="cl"><span class="n">num_rows</span> <span class="o">=</span> <span class="mi">5</span>
</span></span><span class="line"><span class="cl"><span class="n">num_cols</span> <span class="o">=</span> <span class="mi">10</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># Calculate the total number of subplots</span>
</span></span><span class="line"><span class="cl"><span class="n">num_subplots</span> <span class="o">=</span> <span class="n">num_rows</span> <span class="o">*</span> <span class="n">num_cols</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># Create a figure and axes for the subplots</span>
</span></span><span class="line"><span class="cl"><span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">num_rows</span><span class="p">,</span> <span class="n">num_cols</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># Iterate over the MNIST dataset and plot the images</span>
</span></span><span class="line"><span class="cl"><span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_subplots</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="n">image</span><span class="p">,</span> <span class="n">label</span> <span class="o">=</span> <span class="n">train_set</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="c1"># Convert the image tensor to a numpy array</span>
</span></span><span class="line"><span class="cl">    <span class="n">image</span> <span class="o">=</span> <span class="n">image</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="c1"># Get the subplot index</span>
</span></span><span class="line"><span class="cl">    <span class="n">row_idx</span> <span class="o">=</span> <span class="n">i</span> <span class="o">//</span> <span class="n">num_cols</span>
</span></span><span class="line"><span class="cl">    <span class="n">col_idx</span> <span class="o">=</span> <span class="n">i</span> <span class="o">%</span> <span class="n">num_cols</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="c1"># Plot the image in the corresponding subplot</span>
</span></span><span class="line"><span class="cl">    <span class="n">axes</span><span class="p">[</span><span class="n">row_idx</span><span class="p">,</span> <span class="n">col_idx</span><span class="p">]</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;gray&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">axes</span><span class="p">[</span><span class="n">row_idx</span><span class="p">,</span> <span class="n">col_idx</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Label: </span><span class="si">{</span><span class="n">label</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">12</span><span class="p">,</span> <span class="n">pad</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">axes</span><span class="p">[</span><span class="n">row_idx</span><span class="p">,</span> <span class="n">col_idx</span><span class="p">]</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s1">&#39;off&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="c1"># Add a border around each subplot</span>
</span></span><span class="line"><span class="cl">    <span class="n">axes</span><span class="p">[</span><span class="n">row_idx</span><span class="p">,</span> <span class="n">col_idx</span><span class="p">]</span><span class="o">.</span><span class="n">spines</span><span class="p">[</span><span class="s1">&#39;top&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">set_visible</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">axes</span><span class="p">[</span><span class="n">row_idx</span><span class="p">,</span> <span class="n">col_idx</span><span class="p">]</span><span class="o">.</span><span class="n">spines</span><span class="p">[</span><span class="s1">&#39;bottom&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">set_visible</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">axes</span><span class="p">[</span><span class="n">row_idx</span><span class="p">,</span> <span class="n">col_idx</span><span class="p">]</span><span class="o">.</span><span class="n">spines</span><span class="p">[</span><span class="s1">&#39;left&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">set_visible</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">axes</span><span class="p">[</span><span class="n">row_idx</span><span class="p">,</span> <span class="n">col_idx</span><span class="p">]</span><span class="o">.</span><span class="n">spines</span><span class="p">[</span><span class="s1">&#39;right&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">set_visible</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">axes</span><span class="p">[</span><span class="n">row_idx</span><span class="p">,</span> <span class="n">col_idx</span><span class="p">]</span><span class="o">.</span><span class="n">spines</span><span class="p">[</span><span class="s1">&#39;top&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">set_color</span><span class="p">(</span><span class="s1">&#39;gray&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">axes</span><span class="p">[</span><span class="n">row_idx</span><span class="p">,</span> <span class="n">col_idx</span><span class="p">]</span><span class="o">.</span><span class="n">spines</span><span class="p">[</span><span class="s1">&#39;bottom&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">set_color</span><span class="p">(</span><span class="s1">&#39;gray&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">axes</span><span class="p">[</span><span class="n">row_idx</span><span class="p">,</span> <span class="n">col_idx</span><span class="p">]</span><span class="o">.</span><span class="n">spines</span><span class="p">[</span><span class="s1">&#39;left&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">set_color</span><span class="p">(</span><span class="s1">&#39;gray&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">axes</span><span class="p">[</span><span class="n">row_idx</span><span class="p">,</span> <span class="n">col_idx</span><span class="p">]</span><span class="o">.</span><span class="n">spines</span><span class="p">[</span><span class="s1">&#39;right&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">set_color</span><span class="p">(</span><span class="s1">&#39;gray&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># Adjust the spacing between subplots</span>
</span></span><span class="line"><span class="cl"><span class="n">plt</span><span class="o">.</span><span class="n">subplots_adjust</span><span class="p">(</span><span class="n">wspace</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">hspace</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># Set the overall title and styling</span>
</span></span><span class="line"><span class="cl"><span class="n">fig</span><span class="o">.</span><span class="n">suptitle</span><span class="p">(</span><span class="s1">&#39;MNIST Dataset Subplots&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">25</span><span class="p">,</span> <span class="n">fontweight</span><span class="o">=</span><span class="s1">&#39;bold&#39;</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="mf">0.95</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">(</span><span class="n">pad</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># Add a background color to the figure</span>
</span></span><span class="line"><span class="cl"><span class="n">fig</span><span class="o">.</span><span class="n">patch</span><span class="o">.</span><span class="n">set_facecolor</span><span class="p">(</span><span class="s1">&#39;#F8F8F8&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># Display the subplots</span>
</span></span><span class="line"><span class="cl"><span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</span></span></code></pre></div><p>















<figure  >
  <div class="d-flex justify-content-center">
    <div class="w-100" ><img src="/PyTorch/mnist.png" alt="png" loading="lazy" data-zoomable /></div>
  </div></figure>
</p>
<p>Once the dataset is loaded, it becomes readily available for further processing and model training.</p>
<h3 id="data-preprocessing">Data Preprocessing</h3>
<p>Data preprocessing is a critical step that ensures the dataset is in a suitable format for training a deep neural network. Common preprocessing techniques include normalization, resizing, and data augmentation. PyTorch&rsquo;s <code>transforms</code> module provides a range of transformation functions to facilitate these preprocessing operations.</p>
<h4 id="normalization">Normalization</h4>
<p>Normalization is a fundamental preprocessing technique that scales the pixel values to a standardized range. It helps to alleviate the impact of different scales and improves the convergence of the training process. For the MNIST dataset, we can normalize the pixel values to a range of [-1, 1].</p>
<p>To create a preprocessing pipeline specific to the MNIST dataset, use the following code:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">torchvision.transforms</span> <span class="k">as</span> <span class="nn">transforms</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># Define the transformation pipeline</span>
</span></span><span class="line"><span class="cl"><span class="n">transform</span> <span class="o">=</span> <span class="n">transforms</span><span class="o">.</span><span class="n">Compose</span><span class="p">([</span>
</span></span><span class="line"><span class="cl">    <span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">(),</span>               <span class="c1"># Convert PIL image to tensor</span>
</span></span><span class="line"><span class="cl">    <span class="n">transforms</span><span class="o">.</span><span class="n">Normalize</span><span class="p">((</span><span class="mf">0.5</span><span class="p">,),</span> <span class="p">(</span><span class="mf">0.5</span><span class="p">,))</span> <span class="c1"># Normalize the pixel values to the range [-1, 1]</span>
</span></span><span class="line"><span class="cl"><span class="p">])</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># Apply the transformation pipeline to the training set</span>
</span></span><span class="line"><span class="cl"><span class="n">train_set</span><span class="o">.</span><span class="n">transform</span> <span class="o">=</span> <span class="n">transform</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># Apply the transformation pipeline to the test set</span>
</span></span><span class="line"><span class="cl"><span class="n">test_set</span><span class="o">.</span><span class="n">transform</span> <span class="o">=</span> <span class="n">transform</span>
</span></span></code></pre></div><p>In the code snippet above, we use the <code>ToTensor</code> transformation to convert the PIL images in the dataset to tensors, enabling efficient processing within the deep neural network. Subsequently, the <code>Normalize</code> transformation scales the pixel values by subtracting the mean (0.5) and dividing by the standard deviation (0.5), resulting in a range of [-1, 1].</p>
<p>By applying these transformations, the dataset is effectively preprocessed and ready for training.</p>
<h4 id="resizing">Resizing</h4>
<p>Resizing is a preprocessing technique commonly employed when input images have varying dimensions. It ensures that all images within the dataset possess consistent dimensions, simplifying subsequent processing steps. However, for the MNIST dataset, the images are already of uniform size (28x28 pixels), so resizing is not necessary in this case.</p>
<h4 id="data-augmentation">Data Augmentation</h4>
<p>Data augmentation is a powerful technique used to artificially increase the diversity of the training dataset. By applying random transformations to the training images, we introduce additional variations, thereby enhancing the model&rsquo;s ability to generalize. Common data augmentation techniques include random cropping, flipping, rotation, and scaling.</p>
<p>For the MNIST dataset, data augmentation may not be necessary due to its relatively large size and the inherent variability of the handwritten digits. However, it is worth noting that data augmentation can be beneficial for more complex datasets where additional variations can help improve model performance.</p>
<h3 id="train-validation-test-split">Train-Validation-Test Split</h3>
<p>Splitting the dataset into distinct subsets for training, validation, and testing is essential for assessing and fine-tuning the performance of the deep neural network. The train-validation-test split allows us to train the model on one subset, tune hyperparameters on another, and evaluate the final model&rsquo;s generalization on the independent test set.</p>
<p>PyTorch&rsquo;s <code>torch.utils.data.random_split</code> utility simplifies this process. We can split the MNIST dataset into training, validation, and test sets using the following code:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">random_split</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># Define the proportions for the split</span>
</span></span><span class="line"><span class="cl"><span class="n">train_ratio</span> <span class="o">=</span> <span class="mf">0.7</span>
</span></span><span class="line"><span class="cl"><span class="n">val_ratio</span> <span class="o">=</span> <span class="mf">0.15</span>
</span></span><span class="line"><span class="cl"><span class="n">test_ratio</span> <span class="o">=</span> <span class="mf">0.15</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># Compute the sizes of each split</span>
</span></span><span class="line"><span class="cl"><span class="n">train_size</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">train_set</span><span class="p">)</span> <span class="o">*</span> <span class="n">train_ratio</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">val_size</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">train_set</span><span class="p">)</span> <span class="o">*</span> <span class="n">val_ratio</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">test_size</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">train_set</span><span class="p">)</span> <span class="o">-</span> <span class="n">train_size</span> <span class="o">-</span> <span class="n">val_size</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># Perform the random split</span>
</span></span><span class="line"><span class="cl"><span class="n">train_set</span><span class="p">,</span> <span class="n">val_set</span><span class="p">,</span> <span class="n">test_set</span> <span class="o">=</span> <span class="n">random_split</span><span class="p">(</span><span class="n">train_set</span><span class="p">,</span> <span class="p">[</span><span class="n">train_size</span><span class="p">,</span> <span class="n">val_size</span><span class="p">,</span> <span class="n">test_size</span><span class="p">])</span>
</span></span></code></pre></div><p>In the code above, we first import the <code>random_split</code> function from <code>torch.utils.data</code>. We then define the desired proportions for the train, validation, and test sets. The sizes of each split are computed based on these proportions. Finally, we perform the random split on the training set, generating separate datasets for training, validation, and testing.</p>
<p>By splitting the dataset in this manner, we ensure that the model is trained on a sufficiently large training set, validated on a smaller validation set to monitor performance, and tested on an independent test set to evaluate generalization.</p>
<h2 id="4-model-architecture-design">4. Model Architecture Design</h2>
<p>Designing the architecture of your deep neural network involves selecting the number of layers, their sizes, and the activation functions. Additionally, you need to choose a suitable loss function and optimizer for training the model. Proper selection of hyperparameters is crucial for model performance.</p>
<h3 id="neural-network-layers">Neural Network Layers</h3>
<p>PyTorch provides a variety of layer types, such as fully connected layers (<code>nn.Linear</code>), convolutional layers (<code>nn.Conv2d</code>), and recurrent layers (<code>nn.RNN</code>). These layers can be stacked together to form a deep neural network architecture.</p>
<p>The list of available neural network layers, including but not limited to:</p>
<ul>
<li>Convolutional Layers (<code>nn.Conv1d</code>, <code>nn.Conv2d</code>, <code>nn.Conv3d</code>)</li>
<li>Linear Layers (<code>nn.Linear</code>)</li>
<li>Recurrent Layers (<code>nn.RNN</code>, <code>nn.LSTM</code>, <code>nn.GRU</code>)</li>
<li>Dropout Layers (<code>nn.Dropout</code>, <code>nn.Dropout2d</code>, <code>nn.Dropout3d</code>)</li>
<li>Normalization Layers (<code>nn.BatchNorm1d</code>, <code>nn.BatchNorm2d</code>, <code>nn.LayerNorm</code>)</li>
<li>Activation Layers (<code>nn.ReLU</code>, <code>nn.Sigmoid</code>, <code>nn.Tanh</code>, <code>nn.LeakyReLU</code>)</li>
<li>Pooling Layers (<code>nn.MaxPool1d</code>, <code>nn.MaxPool2d</code>, <code>nn.AvgPool1d</code>, <code>nn.AvgPool2d</code>)</li>
<li>Embedding Layers (<code>nn.Embedding</code>)</li>
</ul>
<h3 id="activation-functions">Activation Functions</h3>
<p>Activation functions introduce non-linearity to the model. PyTorch offers a wide range of activation functions, including ReLU (<code>nn.ReLU</code>), sigmoid (<code>nn.Sigmoid</code>), and tanh (<code>nn.Tanh</code>).</p>
<p>Here is a list of available activation functions in PyTorch:</p>
<ul>
<li>ReLU: <code>nn.ReLU</code></li>
<li>Leaky ReLU: <code>nn.LeakyReLU</code></li>
<li>PReLU: <code>nn.PReLU</code></li>
<li>ELU: <code>nn.ELU</code></li>
<li>SELU: <code>nn.SELU</code></li>
<li>GELU: <code>nn.GELU</code></li>
<li>Sigmoid: <code>nn.Sigmoid</code></li>
<li>Tanh: <code>nn.Tanh</code></li>
<li>Softmax: <code>nn.Softmax</code></li>
<li>LogSoftmax: <code>nn.LogSoftmax</code></li>
</ul>
<h3 id="loss-functions">Loss Functions</h3>
<p>The choice of a loss function depends on the task you are trying to solve. PyTorch provides various loss functions, such as mean squared error (<code>nn.MSELoss</code>), cross-entropy loss (<code>nn.CrossEntropyLoss</code>), and binary cross-entropy loss (<code>nn.BCELoss</code>).</p>
<p>Here is a list of available loss functions in PyTorch:</p>
<ul>
<li>BCELoss: <code>nn.BCELoss</code></li>
<li>BCEWithLogitsLoss: <code>nn.BCEWithLogitsLoss</code></li>
<li>CrossEntropyLoss: <code>nn.CrossEntropyLoss</code></li>
<li>CTCLoss: <code>nn.CTCLoss</code></li>
<li>HingeEmbeddingLoss: <code>nn.HingeEmbeddingLoss</code></li>
<li>KLDivLoss: <code>nn.KLDivLoss</code></li>
<li>L1Loss: <code>nn.L1Loss</code></li>
<li>MarginRankingLoss: <code>nn.MarginRankingLoss</code></li>
<li>MSELoss: <code>nn.MSELoss</code></li>
<li>MultiLabelMarginLoss: <code>nn.MultiLabelMarginLoss</code></li>
<li>MultiLabelSoftMarginLoss: <code>nn.MultiLabelSoftMarginLoss</code></li>
<li>MultiMarginLoss: <code>nn.MultiMarginLoss</code></li>
<li>NLLLoss: <code>nn.NLLLoss</code></li>
<li>PoissonNLLLoss: <code>nn.PoissonNLLLoss</code></li>
<li>SmoothL1Loss: <code>nn.SmoothL1Loss</code></li>
<li>SoftMarginLoss: <code>nn.SoftMarginLoss</code></li>
<li>TripletMarginLoss: <code>nn.TripletMarginLoss</code></li>
</ul>
<h3 id="optimizers">Optimizers</h3>
<p>Optimizers are responsible for updating the model&rsquo;s parameters based on the computed gradients during training. PyTorch includes popular optimizers like stochastic gradient descent (<code>optim.SGD</code>), Adam (<code>optim.Adam</code>), and RMSprop (<code>optim.RMSprop</code>).</p>
<p>Here is a list of available optimizers in PyTorch:</p>
<ul>
<li>SGD: <code>torch.optim.SGD</code></li>
<li>Adam: <code>torch.optim.Adam</code></li>
<li>RMSprop: <code>torch.optim.RMSprop</code></li>
<li>Adagrad: <code>torch.optim.Adagrad</code></li>
<li>Adadelta: <code>torch.optim.Adadelta</code></li>
<li>AdamW: <code>torch.optim.AdamW</code></li>
<li>SparseAdam: <code>torch.optim.SparseAdam</code></li>
<li>ASGD: <code>torch.optim.ASGD</code></li>
<li>LBFGS: <code>torch.optim.LBFGS</code></li>
<li>Rprop: <code>torch.optim.Rprop</code></li>
</ul>
<h3 id="hyperparameters">Hyperparameters</h3>
<p>Hyperparameters define the configuration of your model and training process. Examples include the learning rate, batch size, number of epochs, regularization strength, and more. Proper tuning of hyperparameters significantly impacts the model&rsquo;s performance.</p>
<h2 id="5-building-the-deep-neural-network-model">5. Building the Deep Neural Network Model</h2>
<p>To build and train a deep learning model in PyTorch follow the steps outlined below:</p>
<p>Step 1: Define the Model Architecture</p>
<ul>
<li>Start by defining the architecture of your deep learning model. Create a subclass of the <code>torch.nn.Module</code> class and implement the model&rsquo;s structure in the <code>__init__</code> method and the forward pass in the <code>forward</code> method. Specify the layers, activation functions, and any other relevant components of your model.</li>
</ul>
<p>Step 2: Instantiate the Model</p>
<ul>
<li>Once the model class is defined, create an instance of the model by instantiating the class with the appropriate parameters. This includes specifying the input size, hidden layer size, and number of output classes.</li>
</ul>
<p>Step 3: Define the Loss Function</p>
<ul>
<li>To train the model, define a loss function that measures the difference between the predicted output and the true labels. Choose an appropriate loss function based on the problem at hand.</li>
</ul>
<p>Step 4: Define the Optimizer</p>
<ul>
<li>Select an optimizer that will update the model&rsquo;s parameters based on the computed gradients during training. Set the learning rate and other relevant parameters for the optimizer.</li>
</ul>
<p>Step 5: Train the Model</p>
<ul>
<li>Start the training process by iterating over the training dataset in multiple epochs. In each epoch, perform the following steps:
<ul>
<li>Iterate over the mini-batches of data (batch size) from the training dataset.</li>
<li>Perform a forward pass, feeding the input data through the model to obtain predictions.</li>
<li>Calculate the loss by comparing the predictions with the true labels using the defined loss function.</li>
<li>Perform a backward pass to compute the gradients of the loss with respect to the model&rsquo;s parameters.</li>
<li>Use the optimizer to update the model&rsquo;s parameters based on the gradients.</li>
<li>Optionally, track and log the training loss or any other relevant metrics.</li>
</ul>
</li>
</ul>
<p>Step 6: Evaluate the Model</p>
<ul>
<li>After training, evaluate the model&rsquo;s performance on unseen data to assess its generalization ability. Iterate over the validation or test dataset and calculate relevant metrics, such as accuracy, to measure the model&rsquo;s performance.</li>
</ul>
<p>Step 7: Save and Load the Model (Optional)</p>
<ul>
<li>If desired, save the trained model to disk for future use or deployment. Use the <code>torch.save()</code> function to save the model&rsquo;s state dictionary. Later, load the saved model using <code>torch.load()</code> to create an instance of the model and load the saved state.</li>
</ul>
<p>Throughout the process, ensure that the data is appropriately preprocessed, such as scaling, normalizing, or applying any necessary transformations, to ensure compatibility with the model.</p>
<p>By following these steps, you can build and train a deep learning model in PyTorch. Each step contributes to the overall process of model development, training, evaluation, and potentially saving or loading the model for later use.</p>
<p>When comparing the steps involved in building and training a deep learning model in PyTorch and Keras, both frameworks offer distinct advantages and considerations.</p>
<p><strong>PyTorch:</strong></p>
<ul>
<li>
<p><strong>Flexibility and Control</strong>: PyTorch provides a low-level and flexible approach to model development, allowing fine-grained control over the architecture. Its dynamic computational graph enables dynamic network structures and control flow, making it ideal for advanced research and experimentation.</p>
</li>
<li>
<p><strong>Python Integration</strong>: PyTorch seamlessly integrates with the Python ecosystem, leveraging popular libraries like NumPy and SciPy. This integration facilitates efficient data processing, scientific computing, and visualization, empowering researchers with a wide range of tools.</p>
</li>
<li>
<p><strong>Rich Ecosystem</strong>: PyTorch benefits from an active community, resulting in a rich ecosystem of libraries, tools, and pre-trained models. This vibrant community ensures a steady influx of advancements and resources that can be readily utilized.</p>
</li>
</ul>
<p><strong>Keras:</strong></p>
<ul>
<li>
<p><strong>User-Friendly Interface</strong>: Keras offers a high-level API built on top of TensorFlow, providing a simplified and intuitive interface. Its design philosophy prioritizes simplicity and ease of use, making it highly accessible for beginners and enabling rapid model iteration.</p>
</li>
<li>
<p><strong>Quick Prototyping</strong>: Keras abstracts away low-level details, allowing for rapid prototyping and easy experimentation. It provides pre-defined models and modules for common deep learning tasks, facilitating quick implementation and practical applications.</p>
</li>
</ul>
<p>In summary, PyTorch&rsquo;s flexibility and Pythonic approach make it an excellent choice for advanced research and customization, while Keras&rsquo;s simplicity and abstraction make it preferable for practical applications and rapid prototyping. The choice between the two frameworks depends on the project requirements and the desired trade-off between flexibility and ease of use.</p>
<p>In following, we will delve into how to build and train model using PyTorch.</p>
<h3 id="defining-the-model-class">Defining the Model Class</h3>
<p>In the process of building a deep learning model, defining the model class is a fundamental step. This involves creating a class that inherits from the <code>nn.Module</code> base class provided by PyTorch. The model class serves as a blueprint for the architecture of the neural network and encapsulates the layers and the forward propagation logic.</p>
<p>To define the model class, you need to perform the following steps:</p>
<ol>
<li>
<p>Create a class that inherits from <code>nn.Module</code>, such as <code>NeuralNetwork(nn.Module)</code>.</p>
<ul>
<li>By inheriting from <code>nn.Module</code>, you can leverage the functionalities and features provided by PyTorch for model construction and training.</li>
</ul>
</li>
<li>
<p>Define the architecture of the neural network within the <code>__init__</code> method.</p>
<ul>
<li><code>def __init__(self, ... )</code>: In the <code>__init__</code> method, you specify the layers and their configurations. This is where you instantiate and define the individual layers of your network. You can consider <code>input_size, hidden_size, output_size</code> to configure the model.</li>
<li>For example, you can use <code>nn.Linear</code> to create fully connected layers, specifying the input size, output size, and other relevant parameters.
<ul>
<li>
<p><code>super(NeuralNetwork, self).__init__()</code> can be used to initialize the parent class (<code>nn.Module</code>).</p>
<p>In Python, when a class inherits from another class, it is important to call the constructor of the parent class to properly initialize its attributes and functionalities. By using <code>super(NeuralNetwork, self).__init__()</code>, we explicitly call the constructor of the <code>nn.Module</code> class, which is the parent class of our custom model class (<code>NeuralNetwork</code>). This ensures that the necessary initialization steps defined in the parent class are executed before any additional initialization specific to the child class.</p>
</li>
</ul>
</li>
</ul>
</li>
<li>
<p>Implement the forward propagation logic in the <code>forward</code> method.</p>
<ul>
<li>The <code>forward</code> method defines how the input flows through the network and produces the output.</li>
<li>You apply the necessary activation functions and combine the layers to form the desired network architecture.</li>
<li>Ensure that the forward pass is defined sequentially, specifying the sequence of operations that transform the input into the output.</li>
</ul>
</li>
</ol>
<p>Here&rsquo;s an example of a simple fully connected neural network class:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="c1"># Defines a custom model class called NeuralNetwork that inherits from nn.Module. This class will represent our deep learning model.</span>
</span></span><span class="line"><span class="cl"><span class="k">class</span> <span class="nc">NeuralNetwork</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span> 
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_size</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">,</span> <span class="n">output_size</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="nb">super</span><span class="p">(</span><span class="n">NeuralNetwork</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>  <span class="c1"># Initialize the parent class (nn.Module)</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">fc1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">input_size</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">)</span>  <span class="c1"># Create the first fully connected layer</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">fc2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_size</span><span class="p">,</span> <span class="n">output_size</span><span class="p">)</span>  <span class="c1"># Create the second fully connected layer</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">relu</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">()</span>  <span class="c1"># Initialize the ReLU activation function</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="mf">0.5</span><span class="p">)</span>  <span class="c1"># Initialize the dropout layer with a dropout probability of 0.5</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">batchnorm1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm1d</span><span class="p">(</span><span class="n">hidden_size</span><span class="p">)</span>  <span class="c1"># Initialize the batch normalization layer for the first layer</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">batchnorm2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm1d</span><span class="p">(</span><span class="n">output_size</span><span class="p">)</span>  <span class="c1"># Initialize the batch normalization layer for the second layer</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="c1"># Weight initialization</span>
</span></span><span class="line"><span class="cl">        <span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">xavier_uniform_</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">fc1</span><span class="o">.</span><span class="n">weight</span><span class="p">)</span>  <span class="c1"># Initialize the weights of the first fully connected layer using the Xavier uniform distribution</span>
</span></span><span class="line"><span class="cl">        <span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">xavier_uniform_</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">fc2</span><span class="o">.</span><span class="n">weight</span><span class="p">)</span>  <span class="c1"># Initialize the weights of the second fully connected layer using the Xavier uniform distribution</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># Reshape the input tensor to a 2D tensor</span>
</span></span><span class="line"><span class="cl">        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc1</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>  <span class="c1"># Pass the input through the first fully connected layer</span>
</span></span><span class="line"><span class="cl">        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">batchnorm1</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>  <span class="c1"># Apply batch normalization to the output of the first layer</span>
</span></span><span class="line"><span class="cl">        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>  <span class="c1"># Apply the ReLU activation function to the output of the first layer</span>
</span></span><span class="line"><span class="cl">        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>  <span class="c1"># Apply dropout to the output of the first layer</span>
</span></span><span class="line"><span class="cl">        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc2</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>  <span class="c1"># Pass the output through the second fully connected layer</span>
</span></span><span class="line"><span class="cl">        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">batchnorm2</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>  <span class="c1"># Apply batch normalization to the output of the second layer</span>
</span></span><span class="line"><span class="cl">        <span class="k">return</span> <span class="n">x</span>
</span></span></code></pre></div><h3 id="initializing-the-model">Initializing the Model</h3>
<p>To initialize an instance of the model class, you need to specify the input size, hidden size, and output size. For example:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">torchsummary</span> <span class="kn">import</span> <span class="n">summary</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">input_size</span> <span class="o">=</span> <span class="mi">784</span>  <span class="c1"># Number of input features</span>
</span></span><span class="line"><span class="cl"><span class="n">hidden_size</span> <span class="o">=</span> <span class="mi">128</span>  <span class="c1"># Number of hidden units</span>
</span></span><span class="line"><span class="cl"><span class="n">output_size</span> <span class="o">=</span> <span class="mi">10</span>  <span class="c1"># Number of output classes</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">model</span> <span class="o">=</span> <span class="n">NeuralNetwork</span><span class="p">(</span><span class="n">input_size</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">,</span> <span class="n">output_size</span><span class="p">)</span>  <span class="c1"># Create an instance of the NeuralNetwork model</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">summary</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="p">(</span><span class="n">input_size</span><span class="p">,))</span>  <span class="c1"># Print the summary of the model</span>
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" class="chroma"><code class="language-shell" data-lang="shell"><span class="line"><span class="cl">----------------------------------------------------------------
</span></span><span class="line"><span class="cl">        Layer <span class="o">(</span><span class="nb">type</span><span class="o">)</span>               Output Shape         Param <span class="c1">#</span>
</span></span><span class="line"><span class="cl"><span class="o">================================================================</span>
</span></span><span class="line"><span class="cl">            Linear-1                  <span class="o">[</span>-1, 128<span class="o">]</span>         100,480
</span></span><span class="line"><span class="cl">       BatchNorm1d-2                  <span class="o">[</span>-1, 128<span class="o">]</span>             <span class="m">256</span>
</span></span><span class="line"><span class="cl">              ReLU-3                  <span class="o">[</span>-1, 128<span class="o">]</span>               <span class="m">0</span>
</span></span><span class="line"><span class="cl">           Dropout-4                  <span class="o">[</span>-1, 128<span class="o">]</span>               <span class="m">0</span>
</span></span><span class="line"><span class="cl">            Linear-5                   <span class="o">[</span>-1, 10<span class="o">]</span>           1,290
</span></span><span class="line"><span class="cl">       BatchNorm1d-6                   <span class="o">[</span>-1, 10<span class="o">]</span>              <span class="nv">20</span>
</span></span><span class="line"><span class="cl"><span class="o">================================================================</span>
</span></span><span class="line"><span class="cl">Total params: 102,046
</span></span><span class="line"><span class="cl">Trainable params: 102,046
</span></span><span class="line"><span class="cl">Non-trainable params: <span class="m">0</span>
</span></span><span class="line"><span class="cl">----------------------------------------------------------------
</span></span><span class="line"><span class="cl">Input size <span class="o">(</span>MB<span class="o">)</span>: 0.00
</span></span><span class="line"><span class="cl">Forward/backward pass size <span class="o">(</span>MB<span class="o">)</span>: 0.00
</span></span><span class="line"><span class="cl">Params size <span class="o">(</span>MB<span class="o">)</span>: 0.39
</span></span><span class="line"><span class="cl">Estimated Total Size <span class="o">(</span>MB<span class="o">)</span>: 0.40
</span></span><span class="line"><span class="cl">----------------------------------------------------------------
</span></span></code></pre></div><h2 id="6-training-the-model">6. Training the Model</h2>
<h3 id="setting-up-training-parameters">Setting up Training Parameters</h3>
<p>Before training the model, you need to define the training parameters such as the learning rate, batch size, and number of epochs. You also need to specify the loss function and optimizer.</p>
<h3 id="defining-the-loss-function">Defining the Loss Function</h3>
<p>Choose an appropriate loss function based on your task. For example, if you are solving a multi-class classification problem, you can use the cross-entropy loss:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">criterion</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>
</span></span></code></pre></div><h3 id="selecting-the-optimizer">Selecting the Optimizer</h3>
<p>Select an optimizer and provide the model parameters to optimize. For example, to use the Adam optimizer:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">optimizer</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.001</span><span class="p">)</span>
</span></span></code></pre></div><h3 id="define-the-number-of-epochs">Define the Number of Epochs</h3>
<p>The number of epochs determines how many times the model iterates over the entire training dataset. It is essential to find the right balance: too few epochs may result in underfitting, while too many can lead to overfitting. Researchers employ techniques like early stopping and cross-validation to determine the optimal number of epochs. By fine-tuning this parameter, models can achieve optimal performance without unnecessary computational overhead.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="c1"># Define the Number of Epochs</span>
</span></span><span class="line"><span class="cl"><span class="n">num_epochs</span> <span class="o">=</span> <span class="mi">10</span>
</span></span></code></pre></div><h3 id="define-the-batch-size">Define the Batch Size</h3>
<p>The batch size refers to the number of samples processed in each iteration during training. It plays a crucial role in balancing computational efficiency and model performance. Selecting an appropriate batch size is important to ensure efficient memory utilization and computational speed. A small batch size allows the model to update parameters more frequently but may result in noisy gradients and slower convergence. Conversely, a large batch size reduces noise but may lead to longer training times and potential memory limitations. Researchers often experiment with different batch sizes to find the optimal trade-off between accuracy and computational efficiency for their specific problem. It is important to consider hardware limitations, model complexity, and available computational resources when defining the batch size for training deep learning models.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="c1"># Define the Batch Size</span>
</span></span><span class="line"><span class="cl"><span class="n">batch_size</span> <span class="o">=</span> <span class="mi">32</span>
</span></span></code></pre></div><h3 id="creat-dataset-loader">Creat Dataset Loader</h3>
<p>Dataset loaders, such as train_loader and validation_loader, play a crucial role in deep learning. They enable efficient loading and processing of training and validation datasets, respectively. The train_loader iterates through the training data with a specified batch size, allowing for effective model training. The validation_loader evaluates the model&rsquo;s performance on unseen data. By using dataset loaders, researchers can handle large datasets and ensure effective training and evaluation of deep learning models.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="c1"># Create the train_loader</span>
</span></span><span class="line"><span class="cl"><span class="n">train_loader</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span><span class="n">train_set</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># Create the validation_loader</span>
</span></span><span class="line"><span class="cl"><span class="n">validation_loader</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span><span class="n">val_set</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</span></span></code></pre></div><h3 id="training-the-model">Training the Model</h3>
<p>The training loop typically involves iterating over the dataset, performing forward and backward propagation, and updating the model&rsquo;s parameters. Here&rsquo;s an example of a basic training loop using PyTorch:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="c1"># Initialize empty lists to store metrics</span>
</span></span><span class="line"><span class="cl"><span class="n">train_losses</span> <span class="o">=</span> <span class="p">[]</span>
</span></span><span class="line"><span class="cl"><span class="n">val_losses</span> <span class="o">=</span> <span class="p">[]</span>
</span></span><span class="line"><span class="cl"><span class="n">accuracies</span> <span class="o">=</span> <span class="p">[]</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># Proceed with the training loop</span>
</span></span><span class="line"><span class="cl"><span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_epochs</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">    <span class="n">running_loss</span> <span class="o">=</span> <span class="mf">0.0</span>
</span></span><span class="line"><span class="cl">    <span class="n">correct</span> <span class="o">=</span> <span class="mi">0</span>
</span></span><span class="line"><span class="cl">    <span class="n">total</span> <span class="o">=</span> <span class="mi">0</span>
</span></span><span class="line"><span class="cl">    <span class="k">for</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">labels</span> <span class="ow">in</span> <span class="n">train_loader</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">        <span class="n">inputs</span> <span class="o">=</span> <span class="n">inputs</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>  <span class="c1"># Move inputs to the GPU if available</span>
</span></span><span class="line"><span class="cl">        <span class="n">labels</span> <span class="o">=</span> <span class="n">labels</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>  <span class="c1"># Move labels to the GPU if available</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>  <span class="c1"># Zero the gradients</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>  <span class="c1"># Forward pass</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="n">loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>  <span class="c1"># Compute the loss</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>  <span class="c1"># Backward pass and optimization</span>
</span></span><span class="line"><span class="cl">        <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="n">running_loss</span> <span class="o">+=</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span> <span class="o">*</span> <span class="n">inputs</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>  <span class="c1"># Update running loss</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="n">train_loss</span> <span class="o">=</span> <span class="n">running_loss</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">train_set</span><span class="p">)</span>  <span class="c1"># Compute average training loss for the epoch</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&#34;Epoch </span><span class="si">{</span><span class="n">epoch</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="n">num_epochs</span><span class="si">}</span><span class="s2">, Training Loss: </span><span class="si">{</span><span class="n">train_loss</span><span class="si">}</span><span class="s2">&#34;</span><span class="p">)</span>  <span class="c1"># Print training progress</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="c1"># Compute average training loss for the epoch</span>
</span></span><span class="line"><span class="cl">    <span class="n">train_loss</span> <span class="o">=</span> <span class="n">running_loss</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">train_set</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">train_losses</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">train_loss</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="c1"># Perform validation</span>
</span></span><span class="line"><span class="cl">    <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">    <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># Perform validation</span>
</span></span><span class="line"><span class="cl">        <span class="n">validation_loss</span> <span class="o">=</span> <span class="mf">0.0</span>
</span></span><span class="line"><span class="cl">        <span class="n">correct</span> <span class="o">=</span> <span class="mi">0</span>
</span></span><span class="line"><span class="cl">        <span class="n">total</span> <span class="o">=</span> <span class="mi">0</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="k">for</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">labels</span> <span class="ow">in</span> <span class="n">validation_loader</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">            <span class="n">inputs</span> <span class="o">=</span> <span class="n">inputs</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>  <span class="c1"># Move inputs to the GPU if available</span>
</span></span><span class="line"><span class="cl">            <span class="n">labels</span> <span class="o">=</span> <span class="n">labels</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>  <span class="c1"># Move labels to the GPU if available</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">            <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>  <span class="c1"># Forward pass</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">            <span class="n">validation_loss</span> <span class="o">+=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span><span class="o">.</span><span class="n">item</span><span class="p">()</span> <span class="o">*</span> <span class="n">inputs</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>  <span class="c1"># Compute validation loss</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">            <span class="n">_</span><span class="p">,</span> <span class="n">predicted</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">outputs</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">            <span class="n">total</span> <span class="o">+=</span> <span class="n">labels</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">            <span class="n">correct</span> <span class="o">+=</span> <span class="p">(</span><span class="n">predicted</span> <span class="o">==</span> <span class="n">labels</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="c1"># Compute average validation loss and accuracy</span>
</span></span><span class="line"><span class="cl">        <span class="n">val_loss</span> <span class="o">=</span> <span class="n">validation_loss</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">val_set</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="n">val_losses</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">val_loss</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="n">accuracy</span> <span class="o">=</span> <span class="n">correct</span> <span class="o">/</span> <span class="n">total</span> <span class="o">*</span> <span class="mi">100</span>
</span></span><span class="line"><span class="cl">        <span class="n">accuracies</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">accuracy</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="c1"># Print training progress</span>
</span></span><span class="line"><span class="cl">        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&#34;Epoch </span><span class="si">{</span><span class="n">epoch</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="n">num_epochs</span><span class="si">}</span><span class="s2">, Train Loss: </span><span class="si">{</span><span class="n">train_loss</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">, Val Loss: </span><span class="si">{</span><span class="n">val_loss</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">, Accuracy: </span><span class="si">{</span><span class="n">accuracy</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">%&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="s2">&#34;Training complete&#34;</span><span class="p">)</span>
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" class="chroma"><code class="language-shell" data-lang="shell"><span class="line"><span class="cl">Epoch 1/10, Training Loss: 0.3673658960887364
</span></span><span class="line"><span class="cl">Epoch 1/10, Train Loss: 0.3674, Val Loss: 0.1725, Accuracy: 96.02%
</span></span><span class="line"><span class="cl">Epoch 2/10, Training Loss: 0.32074411276408604
</span></span><span class="line"><span class="cl">Epoch 2/10, Train Loss: 0.3207, Val Loss: 0.1643, Accuracy: 95.98%
</span></span><span class="line"><span class="cl">Epoch 3/10, Training Loss: 0.2885793504204069
</span></span><span class="line"><span class="cl">Epoch 3/10, Train Loss: 0.2886, Val Loss: 0.1385, Accuracy: 96.43%
</span></span><span class="line"><span class="cl">Epoch 4/10, Training Loss: 0.26486541454281126
</span></span><span class="line"><span class="cl">Epoch 4/10, Train Loss: 0.2649, Val Loss: 0.1290, Accuracy: 96.68%
</span></span><span class="line"><span class="cl">Epoch 5/10, Training Loss: 0.2510575955793971
</span></span><span class="line"><span class="cl">Epoch 5/10, Train Loss: 0.2511, Val Loss: 0.1246, Accuracy: 96.89%
</span></span><span class="line"><span class="cl">Epoch 6/10, Training Loss: 0.23510122887577328
</span></span><span class="line"><span class="cl">Epoch 6/10, Train Loss: 0.2351, Val Loss: 0.1123, Accuracy: 97.02%
</span></span><span class="line"><span class="cl">Epoch 7/10, Training Loss: 0.22847037938946768
</span></span><span class="line"><span class="cl">Epoch 7/10, Train Loss: 0.2285, Val Loss: 0.1097, Accuracy: 97.16%
</span></span><span class="line"><span class="cl">Epoch 8/10, Training Loss: 0.21747894473870596
</span></span><span class="line"><span class="cl">Epoch 8/10, Train Loss: 0.2175, Val Loss: 0.1063, Accuracy: 97.22%
</span></span><span class="line"><span class="cl">Epoch 9/10, Training Loss: 0.2100531817362422
</span></span><span class="line"><span class="cl">Epoch 9/10, Train Loss: 0.2101, Val Loss: 0.1031, Accuracy: 97.10%
</span></span><span class="line"><span class="cl">Epoch 10/10, Training Loss: 0.20597965082242375
</span></span><span class="line"><span class="cl">Epoch 10/10, Train Loss: 0.2060, Val Loss: 0.1013, Accuracy: 97.33%
</span></span><span class="line"><span class="cl">Training <span class="nb">complete</span>
</span></span></code></pre></div><h3 id="monitoring-training-progress">Monitoring Training Progress</h3>
<p>During training, it&rsquo;s helpful to monitor the training loss, validation loss, and accuracy. You can use these metrics to assess the model&rsquo;s performance and make improvements as necessary. You can also visualize the metrics using libraries like <code>matplotlib</code> or <code>tensorboard</code>.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="c1"># Plot training progress</span>
</span></span><span class="line"><span class="cl"><span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">train_losses</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Train Loss&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">val_losses</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Val Loss&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Epoch&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Loss&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
</span></span><span class="line"><span class="cl"><span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</span></span></code></pre></div><p>















<figure  >
  <div class="d-flex justify-content-center">
    <div class="w-100" ><img src="/PyTorch/log.png" alt="png" loading="lazy" data-zoomable /></div>
  </div></figure>
</p>
<h2 id="7-evaluating-the-model">7. Evaluating the Model</h2>
<h3 id="testing-the-model">Testing the Model</h3>
<p>Once you have trained the model, you can evaluate its performance on unseen data. Create a separate test data loader and use the trained model to make predictions. Compare the predictions with the ground truth labels to compute metrics such as accuracy, precision, recall, and F1 score.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="c1"># Testing the Model</span>
</span></span><span class="line"><span class="cl"><span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>  <span class="c1"># Set the model to evaluation mode</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">test_loss</span> <span class="o">=</span> <span class="mf">0.0</span>
</span></span><span class="line"><span class="cl"><span class="n">correct</span> <span class="o">=</span> <span class="mi">0</span>
</span></span><span class="line"><span class="cl"><span class="n">total</span> <span class="o">=</span> <span class="mi">0</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># Create the test_loader</span>
</span></span><span class="line"><span class="cl"><span class="n">test_loader</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span><span class="n">test_set</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># Disable gradient computation for efficiency</span>
</span></span><span class="line"><span class="cl"><span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
</span></span><span class="line"><span class="cl">    <span class="k">for</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">labels</span> <span class="ow">in</span> <span class="n">test_loader</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">        <span class="n">inputs</span> <span class="o">=</span> <span class="n">inputs</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>  <span class="c1"># Move inputs to the GPU if available</span>
</span></span><span class="line"><span class="cl">        <span class="n">labels</span> <span class="o">=</span> <span class="n">labels</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>  <span class="c1"># Move labels to the GPU if available</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="c1"># Forward pass</span>
</span></span><span class="line"><span class="cl">        <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="c1"># Compute the loss</span>
</span></span><span class="line"><span class="cl">        <span class="n">loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="n">test_loss</span> <span class="o">+=</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span> <span class="o">*</span> <span class="n">inputs</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="c1"># Convert output probabilities to predicted class</span>
</span></span><span class="line"><span class="cl">        <span class="n">_</span><span class="p">,</span> <span class="n">predicted</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">outputs</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="c1"># Update total and correct predictions</span>
</span></span><span class="line"><span class="cl">        <span class="n">total</span> <span class="o">+=</span> <span class="n">labels</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="n">correct</span> <span class="o">+=</span> <span class="p">(</span><span class="n">predicted</span> <span class="o">==</span> <span class="n">labels</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># Compute average test loss and accuracy</span>
</span></span><span class="line"><span class="cl"><span class="n">average_loss</span> <span class="o">=</span> <span class="n">test_loss</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">test_set</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">accuracy</span> <span class="o">=</span> <span class="p">(</span><span class="n">correct</span> <span class="o">/</span> <span class="n">total</span><span class="p">)</span> <span class="o">*</span> <span class="mi">100</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&#34;Test Loss: </span><span class="si">{</span><span class="n">average_loss</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&#34;Accuracy: </span><span class="si">{</span><span class="n">accuracy</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">%&#34;</span><span class="p">)</span>
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" class="chroma"><code class="language-shell" data-lang="shell"><span class="line"><span class="cl">Test Loss: 0.1012
</span></span><span class="line"><span class="cl">Accuracy: 97.13%
</span></span></code></pre></div><p>Also, you can test the model by showing an image along with the predicted label, you can select a random sample from the test dataset and visualize the image using <code>matplotlib</code>. Here&rsquo;s an example of how you can achieve this:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">random</span>
</span></span><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># Set the model to evaluation mode</span>
</span></span><span class="line"><span class="cl"><span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># Select a random sample from the test dataset</span>
</span></span><span class="line"><span class="cl"><span class="n">index</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">test_set</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">image</span><span class="p">,</span> <span class="n">label</span> <span class="o">=</span> <span class="n">test_set</span><span class="p">[</span><span class="n">index</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># Move the image tensor to the same device as the model</span>
</span></span><span class="line"><span class="cl"><span class="n">image</span> <span class="o">=</span> <span class="n">image</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># Move the model to the same device as the image</span>
</span></span><span class="line"><span class="cl"><span class="n">model</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># Forward pass to obtain the predicted label</span>
</span></span><span class="line"><span class="cl"><span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
</span></span><span class="line"><span class="cl">    <span class="n">output</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">image</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">    <span class="n">_</span><span class="p">,</span> <span class="n">predicted_label</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">output</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># Convert the image tensor to a numpy array</span>
</span></span><span class="line"><span class="cl"><span class="n">image</span> <span class="o">=</span> <span class="n">image</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># Display the image and predicted label</span>
</span></span><span class="line"><span class="cl"><span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;gray&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Predicted Label: </span><span class="si">{</span><span class="n">predicted_label</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="si">}</span><span class="s1">, True Label: </span><span class="si">{</span><span class="n">label</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">plt</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s1">&#39;off&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</span></span></code></pre></div><p>















<figure  >
  <div class="d-flex justify-content-center">
    <div class="w-100" ><img src="/PyTorch/test.png" alt="png" loading="lazy" data-zoomable /></div>
  </div></figure>
</p>
<h3 id="model-evaluation-metrics">Model Evaluation Metrics</h3>
<p>The choice of evaluation metrics depends on the specific task you are solving. For classification problems, common metrics include accuracy, precision, recall, and F1 score. For regression tasks, metrics like mean squared error (MSE) or mean absolute error (MAE) are often used.</p>
<p>To visualize the performance of a model on the test dataset, you can create a confusion matrix and a classification report. These visualizations provide insights into how well the model is performing for each class in the test dataset.</p>
<p>The following code demonstrates how to evaluate the performance of a deep learning model using the test dataset. It utilizes the <code>sklearn.metrics</code> module to compute the confusion matrix and classification report, which provide insights into the model&rsquo;s predictions and overall performance.</p>
<p>First, the model is set to evaluation mode using <code>model.eval()</code>. Then, the code iterates through the test loader, disabling gradient computation for efficiency. In each iteration, the model performs a forward pass on the inputs and obtains the predicted class labels. These predicted labels are appended to the <code>predictions</code> list, while the true labels are appended to the <code>true_labels</code> list.</p>
<p>Once all predictions and true labels are collected, the code proceeds to compute the confusion matrix and classification report using the <code>confusion_matrix</code> and <code>classification_report</code> functions from <code>sklearn.metrics</code>. The confusion matrix provides a tabular representation of the model&rsquo;s predictions versus the true labels, while the classification report offers metrics such as precision, recall, and F1 score for each class.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">confusion_matrix</span><span class="p">,</span> <span class="n">classification_report</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># Get the predictions for the test dataset</span>
</span></span><span class="line"><span class="cl"><span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>  <span class="c1"># Set the model to evaluation mode</span>
</span></span><span class="line"><span class="cl"><span class="n">predictions</span> <span class="o">=</span> <span class="p">[]</span>
</span></span><span class="line"><span class="cl"><span class="n">true_labels</span> <span class="o">=</span> <span class="p">[]</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># Disable gradient computation for efficiency</span>
</span></span><span class="line"><span class="cl"><span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
</span></span><span class="line"><span class="cl">    <span class="k">for</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">labels</span> <span class="ow">in</span> <span class="n">test_loader</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">        <span class="n">inputs</span> <span class="o">=</span> <span class="n">inputs</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="n">labels</span> <span class="o">=</span> <span class="n">labels</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="c1"># Forward pass</span>
</span></span><span class="line"><span class="cl">        <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="c1"># Convert output probabilities to predicted class</span>
</span></span><span class="line"><span class="cl">        <span class="n">_</span><span class="p">,</span> <span class="n">predicted</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">outputs</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="c1"># Append the predicted and true labels</span>
</span></span><span class="line"><span class="cl">        <span class="n">predictions</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">predicted</span><span class="o">.</span><span class="n">tolist</span><span class="p">())</span>
</span></span><span class="line"><span class="cl">        <span class="n">true_labels</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">labels</span><span class="o">.</span><span class="n">tolist</span><span class="p">())</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># Compute the confusion matrix and classification report</span>
</span></span><span class="line"><span class="cl"><span class="n">cm</span> <span class="o">=</span> <span class="n">confusion_matrix</span><span class="p">(</span><span class="n">true_labels</span><span class="p">,</span> <span class="n">predictions</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">report</span> <span class="o">=</span> <span class="n">classification_report</span><span class="p">(</span><span class="n">true_labels</span><span class="p">,</span> <span class="n">predictions</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># Print the confusion matrix and classification report</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="s2">&#34;Confusion Matrix:&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="n">cm</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="s2">&#34;</span><span class="se">\n</span><span class="s2">Classification Report:&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="n">report</span><span class="p">)</span>
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" class="chroma"><code class="language-shell" data-lang="shell"><span class="line"><span class="cl">Confusion Matrix:
</span></span><span class="line"><span class="cl"><span class="o">[[</span> <span class="m">877</span>    <span class="m">0</span>    <span class="m">2</span>    <span class="m">1</span>    <span class="m">0</span>    <span class="m">0</span>    <span class="m">4</span>    <span class="m">0</span>    <span class="m">5</span>    0<span class="o">]</span>
</span></span><span class="line"><span class="cl"> <span class="o">[</span>   <span class="m">0</span> <span class="m">1016</span>    <span class="m">6</span>    <span class="m">2</span>    <span class="m">0</span>    <span class="m">1</span>    <span class="m">0</span>    <span class="m">1</span>    <span class="m">2</span>    2<span class="o">]</span>
</span></span><span class="line"><span class="cl"> <span class="o">[</span>   <span class="m">2</span>    <span class="m">6</span>  <span class="m">856</span>    <span class="m">2</span>    <span class="m">3</span>    <span class="m">0</span>    <span class="m">0</span>    <span class="m">4</span>    <span class="m">9</span>    2<span class="o">]</span>
</span></span><span class="line"><span class="cl"> <span class="o">[</span>   <span class="m">0</span>    <span class="m">1</span>    <span class="m">5</span>  <span class="m">887</span>    <span class="m">1</span>    <span class="m">8</span>    <span class="m">0</span>    <span class="m">7</span>    <span class="m">4</span>    4<span class="o">]</span>
</span></span><span class="line"><span class="cl"> <span class="o">[</span>   <span class="m">0</span>    <span class="m">1</span>    <span class="m">2</span>    <span class="m">0</span>  <span class="m">888</span>    <span class="m">0</span>    <span class="m">0</span>    <span class="m">1</span>    <span class="m">0</span>   20<span class="o">]</span>
</span></span><span class="line"><span class="cl"> <span class="o">[</span>   <span class="m">0</span>    <span class="m">1</span>    <span class="m">2</span>   <span class="m">11</span>    <span class="m">5</span>  <span class="m">792</span>    <span class="m">7</span>    <span class="m">1</span>    <span class="m">6</span>    3<span class="o">]</span>
</span></span><span class="line"><span class="cl"> <span class="o">[</span>   <span class="m">1</span>    <span class="m">1</span>    <span class="m">0</span>    <span class="m">0</span>    <span class="m">0</span>    <span class="m">7</span>  <span class="m">877</span>    <span class="m">0</span>    <span class="m">6</span>    0<span class="o">]</span>
</span></span><span class="line"><span class="cl"> <span class="o">[</span>   <span class="m">0</span>    <span class="m">7</span>    <span class="m">6</span>    <span class="m">2</span>    <span class="m">4</span>    <span class="m">0</span>    <span class="m">0</span>  <span class="m">878</span>    <span class="m">3</span>    8<span class="o">]</span>
</span></span><span class="line"><span class="cl"> <span class="o">[</span>   <span class="m">0</span>    <span class="m">3</span>    <span class="m">0</span>    <span class="m">5</span>    <span class="m">2</span>    <span class="m">6</span>    <span class="m">5</span>    <span class="m">0</span>  <span class="m">825</span>    7<span class="o">]</span>
</span></span><span class="line"><span class="cl"> <span class="o">[</span>   <span class="m">2</span>    <span class="m">0</span>    <span class="m">0</span>   <span class="m">11</span>   <span class="m">16</span>    <span class="m">2</span>    <span class="m">0</span>    <span class="m">9</span>    <span class="m">1</span>  846<span class="o">]]</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">Classification Report:
</span></span><span class="line"><span class="cl">              precision    recall  f1-score   support
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">           <span class="m">0</span>       0.99      0.99      0.99       <span class="m">889</span>
</span></span><span class="line"><span class="cl">           <span class="m">1</span>       0.98      0.99      0.98      <span class="m">1030</span>
</span></span><span class="line"><span class="cl">           <span class="m">2</span>       0.97      0.97      0.97       <span class="m">884</span>
</span></span><span class="line"><span class="cl">           <span class="m">3</span>       0.96      0.97      0.97       <span class="m">917</span>
</span></span><span class="line"><span class="cl">           <span class="m">4</span>       0.97      0.97      0.97       <span class="m">912</span>
</span></span><span class="line"><span class="cl">           <span class="m">5</span>       0.97      0.96      0.96       <span class="m">828</span>
</span></span><span class="line"><span class="cl">           <span class="m">6</span>       0.98      0.98      0.98       <span class="m">892</span>
</span></span><span class="line"><span class="cl">           <span class="m">7</span>       0.97      0.97      0.97       <span class="m">908</span>
</span></span><span class="line"><span class="cl">           <span class="m">8</span>       0.96      0.97      0.96       <span class="m">853</span>
</span></span><span class="line"><span class="cl">           <span class="m">9</span>       0.95      0.95      0.95       <span class="m">887</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    accuracy                           0.97      <span class="m">9000</span>
</span></span><span class="line"><span class="cl">   macro avg       0.97      0.97      0.97      <span class="m">9000</span>
</span></span><span class="line"><span class="cl">weighted avg       0.97      0.97      0.97      <span class="m">9000</span>
</span></span></code></pre></div><p>To create a visually appealing confusion matrix, you can use the <code>heatmap</code> function from the <code>seaborn</code> library. This will allow you to plot the confusion matrix as a color-coded image, making it easier to interpret.</p>
<p>Here&rsquo;s an example of how to create a beautiful confusion matrix using <code>seaborn</code>:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
</span></span><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">confusion_matrix</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># Compute the confusion matrix</span>
</span></span><span class="line"><span class="cl"><span class="n">cm</span> <span class="o">=</span> <span class="n">confusion_matrix</span><span class="p">(</span><span class="n">true_labels</span><span class="p">,</span> <span class="n">predictions</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># Create a figure and axes for the confusion matrix plot</span>
</span></span><span class="line"><span class="cl"><span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">8</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># Create a heatmap of the confusion matrix</span>
</span></span><span class="line"><span class="cl"><span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><span class="n">cm</span><span class="p">,</span> <span class="n">annot</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;Blues&#39;</span><span class="p">,</span> <span class="n">fmt</span><span class="o">=</span><span class="s1">&#39;d&#39;</span><span class="p">,</span> <span class="n">cbar</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># Set the axis labels and title</span>
</span></span><span class="line"><span class="cl"><span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;Predicted Labels&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;True Labels&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Confusion Matrix&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># Customize the tick labels</span>
</span></span><span class="line"><span class="cl"><span class="n">tick_labels</span> <span class="o">=</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">cm</span><span class="p">))</span>
</span></span><span class="line"><span class="cl"><span class="n">ax</span><span class="o">.</span><span class="n">set_xticklabels</span><span class="p">(</span><span class="n">tick_labels</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">ax</span><span class="o">.</span><span class="n">set_yticklabels</span><span class="p">(</span><span class="n">tick_labels</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># Rotate the tick labels for better visibility</span>
</span></span><span class="line"><span class="cl"><span class="n">plt</span><span class="o">.</span><span class="n">xticks</span><span class="p">(</span><span class="n">rotation</span><span class="o">=</span><span class="mi">45</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">plt</span><span class="o">.</span><span class="n">yticks</span><span class="p">(</span><span class="n">rotation</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># Show the plot</span>
</span></span><span class="line"><span class="cl"><span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</span></span></code></pre></div><p>















<figure  >
  <div class="d-flex justify-content-center">
    <div class="w-100" ><img src="/PyTorch/conf-matrix.png" alt="png" loading="lazy" data-zoomable /></div>
  </div></figure>
</p>
<p>In this code, we first compute the confusion matrix using the <code>confusion_matrix</code> function from scikit-learn. Then, we create a figure and axes for the plot using <code>plt.subplots</code>. We use the <code>sns.heatmap</code> function to create a heatmap of the confusion matrix, with annotations to display the values in each cell. We customize the colormap (<code>cmap</code>) to use the &lsquo;Blues&rsquo; color scheme and set <code>fmt='d'</code> to display the cell values as integers.</p>
<p>We set the axis labels and title, and customize the tick labels to match the class labels. Finally, we rotate the tick labels for better visibility and display the plot using <code>plt.show()</code>.</p>
<p>This code will produce ab informative visualization of the confusion matrix, allowing you to easily interpret the model&rsquo;s performance on the test dataset.</p>
<h2 id="8-improving-model-performance">8. Improving Model Performance</h2>
<p>To improve the performance of your deep neural network model, you can employ various techniques.</p>
<h3 id="regularization-techniques">Regularization Techniques</h3>
<p>Regularization helps prevent overfitting. Techniques like L1 and L2 regularization (weight decay), dropout, and batch normalization can be applied to the model.</p>
<h3 id="hyperparameter-tuning">Hyperparameter Tuning</h3>
<p>Tuning hyperparameters is crucial for achieving optimal performance. You can use techniques like grid search, random search, or more advanced methods like Bayesian optimization to find the best combination of hyperparameters.</p>
<h3 id="data-augmentation-1">Data Augmentation</h3>
<p>Data augmentation involves applying transformations to the training data to increase its diversity. Techniques like random cropping, flipping, rotation, and scaling can be used to augment the dataset, thereby improving generalization.</p>
<h3 id="transfer-learning">Transfer Learning</h3>
<p>Transfer learning allows you to leverage pre-trained models trained on large datasets and adapt them to your specific task. By using pre-trained models as a starting point, you can significantly reduce training time and achieve good performance with limited labeled data.</p>
<h2 id="9-saving-and-loading-models">9. Saving and Loading Models</h2>
<h3 id="saving-the-model">Saving the Model</h3>
<p>You can save the trained model&rsquo;s parameters to disk for future use or deployment. PyTorch provides the <code>torch.save</code> function to save the model. Here&rsquo;s an example:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span> <span class="s1">&#39;model.pth&#39;</span><span class="p">)</span>
</span></span></code></pre></div><h3 id="loading-the-model">Loading the Model</h3>
<p>To load the saved model, create an instance of the model class and load the saved parameters. Here&rsquo;s an example:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">model</span> <span class="o">=</span> <span class="n">NeuralNetwork</span><span class="p">(</span><span class="n">input_size</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">,</span> <span class="n">output_size</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">model</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s1">&#39;model.pth&#39;</span><span class="p">))</span>
</span></span><span class="line"><span class="cl"><span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
</span></span></code></pre></div><h2 id="10-conclusion">10. Conclusion</h2>
<p>In this tutorial, we covered the complete process of implementing a deep neural network using PyTorch. We explored data loading and preprocessing, model architecture design, training, evaluation, and techniques for improving model performance. By leveraging PyTorch&rsquo;s capabilities, you can build and train powerful deep learning models for a wide range of tasks.</p>
<h2 id="11-references">11. References</h2>
<p>Here are some references that you may find useful for further exploration:</p>
<ul>
<li>PyTorch documentation: <a href="https://pytorch.org/docs/" target="_blank" rel="noopener">https://pytorch.org/docs/</a></li>
<li>PyTorch tutorials: <a href="https://pytorch.org/tutorials/" target="_blank" rel="noopener">https://pytorch.org/tutorials/</a></li>
<li>Official PyTorch GitHub repository: <a href="https://github.com/pytorch/pytorch" target="_blank" rel="noopener">https://github.com/pytorch/pytorch</a></li>
</ul>

    </div>

    





<div class="article-tags">
  
  <a class="badge badge-light" href="/tag/deep-learning/">Deep Learning</a>
  
  <a class="badge badge-light" href="/tag/neural-networks/">Neural Networks</a>
  
  <a class="badge badge-light" href="/tag/pytorch/">PyTorch</a>
  
</div>



<div class="share-box">
  <ul class="share">
    
      
      
      
        
      
      
      
      
      
      
      
      <li>
        <a href="https://twitter.com/intent/tweet?url=https%3A%2F%2Farmanasq.github.io%2FDeep-Learning%2FPyTorch-DNN%2F&amp;text=Deep&#43;Neural&#43;Network&#43;Implementation&#43;Using&#43;PyTorch" target="_blank" rel="noopener" class="share-btn-twitter" aria-label="twitter">
          <i class="fab fa-twitter"></i>
        </a>
      </li>
    
      
      
      
        
      
      
      
      
      
      
      
      <li>
        <a href="https://www.facebook.com/sharer.php?u=https%3A%2F%2Farmanasq.github.io%2FDeep-Learning%2FPyTorch-DNN%2F&amp;t=Deep&#43;Neural&#43;Network&#43;Implementation&#43;Using&#43;PyTorch" target="_blank" rel="noopener" class="share-btn-facebook" aria-label="facebook">
          <i class="fab fa-facebook"></i>
        </a>
      </li>
    
      
      
      
        
      
      
      
      
      
      
      
        
      
      <li>
        <a href="mailto:?subject=Deep%20Neural%20Network%20Implementation%20Using%20PyTorch&amp;body=https%3A%2F%2Farmanasq.github.io%2FDeep-Learning%2FPyTorch-DNN%2F" target="_blank" rel="noopener" class="share-btn-email" aria-label="envelope">
          <i class="fas fa-envelope"></i>
        </a>
      </li>
    
      
      
      
        
      
      
      
      
      
      
      
      <li>
        <a href="https://www.linkedin.com/shareArticle?url=https%3A%2F%2Farmanasq.github.io%2FDeep-Learning%2FPyTorch-DNN%2F&amp;title=Deep&#43;Neural&#43;Network&#43;Implementation&#43;Using&#43;PyTorch" target="_blank" rel="noopener" class="share-btn-linkedin" aria-label="linkedin-in">
          <i class="fab fa-linkedin-in"></i>
        </a>
      </li>
    
      
      
      
        
      
      
      
      
      
      
      
      <li>
        <a href="whatsapp://send?text=Deep&#43;Neural&#43;Network&#43;Implementation&#43;Using&#43;PyTorch%20https%3A%2F%2Farmanasq.github.io%2FDeep-Learning%2FPyTorch-DNN%2F" target="_blank" rel="noopener" class="share-btn-whatsapp" aria-label="whatsapp">
          <i class="fab fa-whatsapp"></i>
        </a>
      </li>
    
      
      
      
        
      
      
      
      
      
      
      
      <li>
        <a href="https://service.weibo.com/share/share.php?url=https%3A%2F%2Farmanasq.github.io%2FDeep-Learning%2FPyTorch-DNN%2F&amp;title=Deep&#43;Neural&#43;Network&#43;Implementation&#43;Using&#43;PyTorch" target="_blank" rel="noopener" class="share-btn-weibo" aria-label="weibo">
          <i class="fab fa-weibo"></i>
        </a>
      </li>
    
  </ul>
</div>











  
  



  
  
  
    
  
  
  
  <div class="media author-card content-widget-hr">
    
      
      <a href="https://armanasq.github.io/"><img class="avatar mr-3 avatar-circle" src="/authors/admin/avatar_hu423262b037e945bf3d00a3d75617f940_247637_270x270_fill_q75_lanczos_center.jpeg" alt="Arman Asgharpoor Golroudbari"></a>
    

    <div class="media-body">
      <h5 class="card-title"><a href="https://armanasq.github.io/">Arman Asgharpoor Golroudbari</a></h5>
      <h6 class="card-subtitle">Space-AI Researcher</h6>
      <p class="card-text">My research interests revolve around planetary rovers and spacecraft vision-based navigation.</p>
      <ul class="network-icon" aria-hidden="true">
  
    
    
    
      
    
    
    
    
    
      
    
    <li>
      <a href="/#contact" >
        <i class="fas fa-comment-alt"></i>
      </a>
    </li>
  
    
    
    
      
    
    
    
    
    
    <li>
      <a href="mailto:a.asgharpoor1993@gmail.com" >
        <i class="fas fa-envelope"></i>
      </a>
    </li>
  
    
    
    
    
    
    
    
      
    
    <li>
      <a href="https://scholar.google.com/citations?user=IlAgF9UAAAAJ&amp;hl=en" target="_blank" rel="noopener">
        <i class="ai ai-google-scholar"></i>
      </a>
    </li>
  
    
    
    
      
    
    
    
    
    
      
    
    <li>
      <a href="https://github.com/armanasq" target="_blank" rel="noopener">
        <i class="fab fa-github"></i>
      </a>
    </li>
  
    
    
    
      
    
    
    
    
    
      
    
    <li>
      <a href="https://linkedin.com/in/asgharpoor" target="_blank" rel="noopener">
        <i class="fab fa-linkedin"></i>
      </a>
    </li>
  
    
    
    
    
    
    
    
      
    
    <li>
      <a href="https://orcid.org/my-orcid?orcid=0000-0001-6271-4533" target="_blank" rel="noopener">
        <i class="ai ai-orcid"></i>
      </a>
    </li>
  
    
    
    
    
    
    
    
      
    
    <li>
      <a href="https://www.webofscience.com/wos/author/record/IAN-3152-2023" target="_blank" rel="noopener">
        <i class="ai ai-publons"></i>
      </a>
    </li>
  
    
    
    
    
    
    
    
      
    
    <li>
      <a href="https://researchgate.net/profile/Arman_Asgharpoor" target="_blank" rel="noopener">
        <i class="ai ai-researchgate"></i>
      </a>
    </li>
  
    
    
    
    
    
    
    
      
    
    <li>
      <a href="/uploads/cv.pdf" >
        <i class="ai ai-cv"></i>
      </a>
    </li>
  
</ul>

    </div>
  </div>









  
  
  

  

  
  <section id="comments">
    
  
  <script src="https://giscus.app/client.js"
          data-repo="Armanasq/Armanasq.github.io"
          data-repo-id="R_kgDOJi13ZQ"
          data-category="[ENTER CATEGORY NAME HERE]"
          data-category-id="[ENTER CATEGORY ID HERE]"
          data-mapping="pathname"
          data-strict="0"
          data-reactions-enabled="1"
          data-emit-metadata="0"
          data-input-position="top"
          data-theme="preferred_color_scheme"
          data-lang="en"
          data-loading="lazy"
          crossorigin="anonymous"
          async>
  </script>


  </section>
  










  </div>
</article>
  </div>

  <div class="page-footer">
    
    
    <div class="container">
      <footer class="site-footer">

  












  
  
  
  
  













  
  
  

  
  
    
  
  
    
  

  

  
  <p class="powered-by copyright-license-text">
    ¬© 2024 Me. This work is licensed under <a href="https://creativecommons.org/licenses/by-nc-nd/4.0" rel="noopener noreferrer" target="_blank">CC BY NC ND 4.0</a>
  </p>
  

  <p class="powered-by footer-license-icons">
    <a href="https://creativecommons.org/licenses/by-nc-nd/4.0" rel="noopener noreferrer" target="_blank" aria-label="Creative Commons">
      <i class="fab fa-creative-commons fa-2x" aria-hidden="true"></i>
      <i class="fab fa-creative-commons-by fa-2x" aria-hidden="true"></i>
      
        <i class="fab fa-creative-commons-nc fa-2x" aria-hidden="true"></i>
      
      
        <i class="fab fa-creative-commons-nd fa-2x" aria-hidden="true"></i>
      
    </a>
  </p>





  <p class="powered-by">
    
    
    
      
      
      
      
      
      
      Published with <a href="https://wowchemy.com/?utm_campaign=poweredby" target="_blank" rel="noopener">Wowchemy</a> ‚Äî the free, <a href="https://github.com/wowchemy/wowchemy-hugo-themes" target="_blank" rel="noopener">open source</a> website builder that empowers creators.
    
  </p>
</footer>

    </div>
    
  </div>

  


<script src="/js/vendor-bundle.min.938a3a7554cd9f6602290411f64d2617.js"></script>




  

  
  

  













  
  <script id="search-hit-fuse-template" type="text/x-template">
    <div class="search-hit" id="summary-{{key}}">
      <div class="search-hit-content">
        <div class="search-hit-name">
          <a href="{{relpermalink}}">{{title}}</a>
          <div class="article-metadata search-hit-type">{{type}}</div>
          <p class="search-hit-description">{{snippet}}</p>
        </div>
      </div>
    </div>
  </script>
  
    <script src="https://cdn.jsdelivr.net/gh/krisk/Fuse@v3.2.1/dist/fuse.min.js" integrity="sha512-o38bmzBGX+hD3JHWUFCDA09btWaqrNmoJ3RXLlrysA7PP01Kgs4UlE4MhelE1v5dJR3+cxlR4qQlotsW7jKsnw==" crossorigin="anonymous"></script>
    <script src="https://cdn.jsdelivr.net/gh/julmot/mark.js@8.11.1/dist/jquery.mark.min.js" integrity="sha512-mhbv5DqBMgrWL+32MmsDOt/OAvqr/cHimk6B8y/bx/xS88MVkYGPiVv2ixKVrkywF2qHplNRUvFsAHUdxZ3Krg==" crossorigin="anonymous"></script>
  












  
  
  
  
  
  
  

















<script id="page-data" type="application/json">{"use_headroom":true}</script>


  <script src="/js/wowchemy-headroom.db4755770454eb63685f8de785c0a172.js" type="module"></script>
<style>
    .markmap > svg {
      width: 100%;
      height: 100%;
    }
  </style>
  <script>
    window.markmap = {
      autoLoader: {
        manual: false,
        onReady() {
          const { autoLoader, builtInPlugins } = window.markmap;
          
          autoLoader.transformPlugins = builtInPlugins.filter(plugin => plugin.name !== 'prism');
        },
      },
    };
  </script>
  <script src="https://cdn.jsdelivr.net/npm/markmap-autoloader"></script>









  
  


<script src="/en/js/wowchemy.min.85070d5fe00d43eaedff44310b81dc2c.js"></script>







  
<div id="modal" class="modal fade" role="dialog">
  <div class="modal-dialog">
    <div class="modal-content">
      <div class="modal-header">
        <h5 class="modal-title">Cite</h5>
        <button type="button" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body">
        
        <pre><code></code></pre>
      </div>
      <div class="modal-footer">
        <a class="btn btn-outline-primary my-1 js-copy-cite" href="#" target="_blank">
          <i class="fas fa-copy"></i> Copy
        </a>
        <a class="btn btn-outline-primary my-1 js-download-cite" href="#" target="_blank">
          <i class="fas fa-download"></i> Download
        </a>
        <div id="modal-error"></div>
      </div>
    </div>
  </div>
</div>


  <script src="/js/wowchemy-publication.68f8d7090562ca65fc6d3cb3f8f2d2cb.js" type="module"></script>













  
    
      
      <!DOCTYPE html>
<html>
<head>
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-55GQYC5GYC"></script>

<style>
  .myImg {
    border-radius: 5px;
    cursor: pointer;
    transition: 0.3s;
    display: block;
    margin-left: auto;
    margin-right: auto;
  }

  .myImg:hover {
    opacity: 0.7;
    cursor: pointer;
  }

   
  .modal-img {
    display: none;  
    position: fixed;  
    z-index: 1;  
    padding-top: 150px;  
    left: 0;
    top: 0px;
    width: 100%;  
    height: 100%;  
    overflow: visible;  
    background-color: rgb(0, 0, 0);  
    background-color: rgba(0, 0, 0, 0.6);  
    margin-left: auto;
    margin-right: auto;
  }

   
  .modal-content {
    display: block;
    margin-left: auto;
    margin-right: auto;
    max-width: 80%;
    max-height: 80%;

  }

   
  #caption {
    margin-left: auto;
    margin-right: auto;
    width: 80%;
    max-width: 700px;
    text-align: center;
    padding: 10px 0;

  }

   
  .modal-content,
  #caption {
    -webkit-animation-name: zoom;
    -webkit-animation-duration: 0.6s;
    animation-name: zoom;
    animation-duration: 0.6s;
    margin-left: auto;
    margin-right: auto;
  }

  @-webkit-keyframes zoom {
    from {
      -webkit-transform: scale(0);
    }
    to {
      -webkit-transform: scale(1);
    }
  }

  @keyframes zoom {
    from {
      transform: scale(0);
    }
    to {
      transform: scale(1);
    }
  }

   
  
 .modal-close {
    position: absolute;
    top: -55px;
    right: 0;
    font-size: 40px;
    font-weight: bold;
    transition: 0.3s;
    cursor: pointer;
  }

  .modal-close:hover,
  .modal-close:focus {
    color: #bbb;
    text-decoration: none;
  }

   
  @media only screen and (max-width: 900px) {
    .modal-content {
      width: 90%;
    }
  }

  .test:hover {
    scale: 1.2;
  }







  .navbar-nav {
    font-size:20px;
    font-family: Merriweather,sans-serif;
  }

  .robotic-section-container {
    display: flex;
    flex-wrap: wrap;
    justify-content: space-between;
    max-width: 1200px;
    margin: 0 auto;
  }
  
  .robotic-section {
    flex-basis: calc(30.33% - 12px);
    margin: 10px;
    background-color: #fff;
    box-shadow: 0 2px 4px rgba(0, 0, 0, 0.1);
    border-radius: 8px;
    transition: box-shadow 0.3s ease-in-out;
    overflow: hidden;
  }
  
  .robotic-section:hover {
    box-shadow: 0 4px 8px rgba(0, 0, 0, 0.2);
  }
  
  .robotic-section-content {
    text-align: center;
    padding: 20px;
    display: flex;
    flex-direction: column;
    justify-content: space-between;
    height: 100%;
  }
  
  .robotic-section-content .image-placeholder {
    width: 300px;
    height: 300px;
    margin: 0 auto;
    display: flex;
    align-items: center;
    justify-content: center;
    background-color: #f1f1f1;
  }
  
  .robotic-section-content .image-placeholder img {
    max-width: 100%;
    max-height: 100%;
    object-fit: contain;
  }
  
  .robotic-section-content-h2 {
    margin-top: 10px;
    font-size: 1.rem;
    font-weight: bold;
    color: #333;
  }
  
  .robotic-section-content-h2 :hover{
    font-size: 10px
  }
  .robotic-section-content-h2 {
    margin-top: 10px;
    color: #777;
    font-size: 1.2rem;
  }
  
  .robotic-section-content .text-placeholder {
    height: 80px;
    background-color: #f1f1f1;
  }
  
  .robotic-section-content a {
    display: inline-block;
    margin-top: 20px;
    padding: 10px 20px;
    background-color: #FF4081;
    color: #fff;
    text-decoration: none;
    border-radius: 4px;
    font-weight: bold;
    transition: background-color 0.3s ease-in-out;
  }
  
  .robotic-section-content a:hover {
    background-color: #E91E63;
  }
  
   
  @media (max-width: 768px) {
    .robotic-section {
      flex-basis: calc(50% - 40px);
    }
  }
  
   
  @media (max-width: 480px) {
    .robotic-section {
      flex-basis: 100%;
    }
  }
</style>
</head>
<body>

<div id="myModal" class="modal-img">
  <div class="modal-content">
    <span class="modal-close">&times;</span>
    <img id="img01" style="margin-left: auto; margin-right: auto;">
    <div id="caption"></div>
  </div>
</div>




<script>
    
    var modal = document.getElementById("myModal");
    
    
    var images = document.querySelectorAll("img.myImg");
    
    
    var modalImg = document.getElementById("img01");
    var captionText = document.getElementById("caption");
    
    
    for (var i = 0; i < images.length; i++) {
      
      images[i].setAttribute("data-src", images[i].src);
      
      images[i].addEventListener("click", function() {
        
        modalImg.src = this.getAttribute("data-src");
        captionText.innerHTML = this.alt;
        
        modal.style.display = "block";
      });
    }
    
    
    var modalClose = document.querySelector(".modal-content .modal-close");
    
    
    modalClose.onclick = function() {
      modal.style.display = "none";
    };
    
















    
    </script>
    
    </body>
    </html>
      
    
  






</body>
</html>
